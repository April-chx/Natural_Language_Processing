{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [t.strip().split(' ')[-1] for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- -X- O\\n',open(\"../data/conll03/deu.train\", encoding=\"ISO-8859-1\").readlines())) if len(t.strip().split(' '))>1]\n",
    "tags = sorted(list(set(tags)))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def if_has_W(feature):\n",
    "    if feature not in W:\n",
    "        return 0\n",
    "    else:\n",
    "        return W[feature]\n",
    "\n",
    "\n",
    "def Pre_Next(): # ('NN','NN')\n",
    "    P_tags  =[] \n",
    "    for pt in tags:\n",
    "        tp_P_tags = []\n",
    "        for nt in tags:\n",
    "            tp_P_tags.append(if_has_W(('pt '+nt,'t '+pt)))\n",
    "        P_tags.append(tp_P_tags)\n",
    "    P_tags = np.asarray(P_tags)\n",
    "    return P_tags\n",
    "\n",
    "\n",
    "def hmm_viterbi(W, words):\n",
    "    y_pred = []\n",
    "    i= 0\n",
    "    aug_words = ['__SENTINEL__', '__SENTINEL__'] + words + ['__SENTINEL__', '__SENTINEL__']\n",
    "    for ppw, pw, w, nw, nnw in zip(aug_words, aug_words[1:], aug_words[2:], aug_words[3:], aug_words[4:]):\n",
    "        # NOTE: No pt, ppt attribs currently\n",
    "        attribs = {'ppw ' + ppw,\n",
    "                   'pw ' + pw,\n",
    "                   'w ' + w,\n",
    "                   'nw ' + nw,\n",
    "                   'nnw ' + nnw,\n",
    "                   }\n",
    "        for j in range(1, 5):\n",
    "            attribs.add('pref ' + w[:j])\n",
    "            attribs.add('suff ' + w[-j:][::-1])\n",
    "        if re.search('[0-9]', w):\n",
    "            attribs.add('dig __NONE__')\n",
    "        if re.search('[A-Z]', w):\n",
    "            attribs.add('uc __NONE__')\n",
    "        if '-' in w:\n",
    "            attribs.add('hyph __NONE__')\n",
    "        \n",
    "        score_list = []\n",
    "        for tag in tags:\n",
    "            score = 0\n",
    "            for a in attribs:\n",
    "                if (a, tag) in W:\n",
    "                    score += W[(a, tag)]\n",
    "            score_list.append(score)\n",
    "        \n",
    "        #Viterbi\n",
    "        if i == 0:\n",
    "            data = words[i]\n",
    "            first_level = []\n",
    "            for tag_number in range(len(tags)):   \n",
    "                first_level.append((if_has_W(('pt '+'','t '+tag))+score_list[tag_number]))\n",
    "            y_pred.append(tags[first_level.index(max(first_level))])\n",
    "            next_value = first_level\n",
    "        else:\n",
    "            data = words[i]\n",
    "            probility = ((next_value + Pre_Next()).T + [score_list[tag_number] for tag_number in range(len(tags))]).T\n",
    "            y_pred.append(tags[probility.max(axis=1).argmax()])\n",
    "            next_value = probility.max(axis=1)\n",
    "\n",
    "        i+=1\n",
    "    return y_pred\n",
    "\n",
    "def create_features(words, word_tags):\n",
    "    loc = 0\n",
    "    w_temp = {}\n",
    "    aug_words = ['__SENTINEL__', '__SENTINEL__'] + words + ['__SENTINEL__', '__SENTINEL__']\n",
    "\n",
    "    for ppw, pw, w, nw, nnw in zip(aug_words, aug_words[1:], aug_words[2:], aug_words[3:], aug_words[4:]):\n",
    "        # NOTE: No pt, ppt attribs currently\n",
    "        attribs = {'ppw ' + ppw,\n",
    "                   'pw ' + pw,\n",
    "                   'w ' + w,\n",
    "                   'nw ' + nw,\n",
    "                   'nnw ' + nnw,\n",
    "                   }\n",
    "        for j in range(1, 5):\n",
    "            attribs.add('pref ' + w[:j])\n",
    "            attribs.add('suff ' + w[-j:][::-1])\n",
    "        if re.search('[0-9]', w):\n",
    "            attribs.add('dig __NONE__')\n",
    "        if re.search('[A-Z]', w):\n",
    "            attribs.add('uc __NONE__')\n",
    "        if '-' in w:\n",
    "            attribs.add('hyph __NONE__')\n",
    "        for a in attribs:\n",
    "            if (a, word_tags[loc]) in w_temp:\n",
    "                w_temp[(a, word_tags[loc])] += 1\n",
    "            else: w_temp[(a, word_tags[loc])] = 1\n",
    "        loc += 1\n",
    "        \n",
    "        \n",
    "    for i in range(len(word_tags)+1):\n",
    "        if i == 0:\n",
    "            first_tag = 'pt '+''\n",
    "        else:\n",
    "            first_tag = 'pt '+word_tags[i-1]\n",
    "        \n",
    "        if i == len(word_tags):\n",
    "            next_tag = 't '+''\n",
    "        else:\n",
    "            next_tag = 't '+word_tags[i]\n",
    "            \n",
    "            if (first_tag,next_tag) not in w_temp:\n",
    "                w_temp[(first_tag,next_tag)] = 0.001#create_trans((tags[i-1],tags[i]))\n",
    "            else:\n",
    "                w_temp[(first_tag,next_tag)] += 0.001#create_trans((tags[i-1],tags[i]))\n",
    "\n",
    "    return w_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Ereignis', 'Ereignis', 'NN', 'I-NC', 'O'],\n",
       "  ['und', 'und', 'KON', 'O', 'O'],\n",
       "  ['Erzählung', 'Erzählung', 'NN', 'I-NC', 'O'],\n",
       "  ['oder', 'oder', 'KON', 'I-NC', 'O'],\n",
       "  [':', ':', '$.', 'O', 'O']]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- -X- O\\n',open(\"../data/conll03/deu.train\", encoding=\"ISO-8859-1\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_train = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Großer', 'Große', 'NN', 'I-NC', 'O'],\n",
       "  ['Foto-Wettbeweb', '<unknown>', 'NN', 'I-NC', 'O'],\n",
       "  ['\"', '\"', '$(', 'O', 'O'],\n",
       "  ['Nordendler', '<unknown>', 'NN', 'I-NC', 'I-ORG'],\n",
       "  ['\"', '\"', '$(', 'O', 'O'],\n",
       "  ['laden', 'laden', 'VVFIN', 'I-VC', 'O'],\n",
       "  ['die', 'd', 'ART', 'I-NC', 'O'],\n",
       "  ['Nordendler', '<unknown>', 'NN', 'I-NC', 'I-MISC'],\n",
       "  ['ein', 'ein', 'ART', 'B-NC', 'O']]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- -X- O\\n',open(\"../data/conll03/deu.testa\", encoding=\"ISO-8859-1\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_pred = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_pred[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 5200 phrases; correct: 2164.\n",
      "accuracy:  91.37%; precision:  41.62%; recall:  44.78%; FB1:  43.14\n",
      "              LOC: precision:  43.15%; recall:  61.30%; FB1:  50.65\n",
      "             MISC: precision:  55.57%; recall:  38.02%; FB1:  45.15\n",
      "              ORG: precision:  31.80%; recall:  26.11%; FB1:  28.67\n",
      "              PER: precision:  40.40%; recall:  52.25%; FB1:  45.56\n",
      "\n",
      "epoch = 2\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4116 phrases; correct: 2042.\n",
      "accuracy:  92.27%; precision:  49.61%; recall:  42.25%; FB1:  45.64\n",
      "              LOC: precision:  51.12%; recall:  61.98%; FB1:  56.03\n",
      "             MISC: precision:  60.86%; recall:  36.34%; FB1:  45.51\n",
      "              ORG: precision:  36.89%; recall:  32.31%; FB1:  34.45\n",
      "              PER: precision:  54.53%; recall:  38.69%; FB1:  45.26\n",
      "\n",
      "epoch = 3\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4384 phrases; correct: 2283.\n",
      "accuracy:  92.88%; precision:  52.08%; recall:  47.24%; FB1:  49.54\n",
      "              LOC: precision:  50.07%; recall:  60.71%; FB1:  54.88\n",
      "             MISC: precision:  69.11%; recall:  36.34%; FB1:  47.63\n",
      "              ORG: precision:  39.51%; recall:  37.79%; FB1:  38.63\n",
      "              PER: precision:  59.16%; recall:  52.11%; FB1:  55.41\n",
      "\n",
      "epoch = 4\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4103 phrases; correct: 2279.\n",
      "accuracy:  93.10%; precision:  55.54%; recall:  47.15%; FB1:  51.01\n",
      "              LOC: precision:  61.56%; recall:  50.04%; FB1:  55.21\n",
      "             MISC: precision:  60.67%; recall:  45.05%; FB1:  51.70\n",
      "              ORG: precision:  40.75%; recall:  37.63%; FB1:  39.13\n",
      "              PER: precision:  61.43%; recall:  54.68%; FB1:  57.85\n",
      "\n",
      "epoch = 5\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4569 phrases; correct: 2429.\n",
      "accuracy:  93.20%; precision:  53.16%; recall:  50.26%; FB1:  51.67\n",
      "              LOC: precision:  54.28%; recall:  60.63%; FB1:  57.28\n",
      "             MISC: precision:  52.53%; recall:  44.16%; FB1:  47.98\n",
      "              ORG: precision:  46.01%; recall:  36.66%; FB1:  40.81\n",
      "              PER: precision:  57.51%; recall:  57.96%; FB1:  57.73\n",
      "\n",
      "epoch = 6\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4620 phrases; correct: 2441.\n",
      "accuracy:  93.32%; precision:  52.84%; recall:  50.51%; FB1:  51.64\n",
      "              LOC: precision:  53.53%; recall:  63.51%; FB1:  58.09\n",
      "             MISC: precision:  57.92%; recall:  43.47%; FB1:  49.66\n",
      "              ORG: precision:  42.44%; recall:  42.55%; FB1:  42.49\n",
      "              PER: precision:  59.49%; recall:  51.68%; FB1:  55.31\n",
      "\n",
      "epoch = 7\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4012 phrases; correct: 2298.\n",
      "accuracy:  93.46%; precision:  57.28%; recall:  47.55%; FB1:  51.96\n",
      "              LOC: precision:  57.80%; recall:  61.47%; FB1:  59.58\n",
      "             MISC: precision:  69.14%; recall:  36.83%; FB1:  48.06\n",
      "              ORG: precision:  47.52%; recall:  33.20%; FB1:  39.09\n",
      "              PER: precision:  58.33%; recall:  56.25%; FB1:  57.27\n",
      "\n",
      "epoch = 8\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4450 phrases; correct: 2491.\n",
      "accuracy:  93.63%; precision:  55.98%; recall:  51.54%; FB1:  53.67\n",
      "              LOC: precision:  53.97%; recall:  65.54%; FB1:  59.20\n",
      "             MISC: precision:  72.09%; recall:  36.83%; FB1:  48.75\n",
      "              ORG: precision:  45.39%; recall:  41.26%; FB1:  43.22\n",
      "              PER: precision:  60.71%; recall:  59.46%; FB1:  60.08\n",
      "\n",
      "epoch = 9\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3798 phrases; correct: 2261.\n",
      "accuracy:  93.55%; precision:  59.53%; recall:  46.78%; FB1:  52.39\n",
      "              LOC: precision:  64.44%; recall:  57.07%; FB1:  60.53\n",
      "             MISC: precision:  63.38%; recall:  38.22%; FB1:  47.68\n",
      "              ORG: precision:  51.41%; recall:  41.18%; FB1:  45.73\n",
      "              PER: precision:  60.05%; recall:  49.25%; FB1:  54.12\n",
      "\n",
      "epoch = 10\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4288 phrases; correct: 2446.\n",
      "accuracy:  93.65%; precision:  57.04%; recall:  50.61%; FB1:  53.63\n",
      "              LOC: precision:  55.47%; recall:  63.59%; FB1:  59.25\n",
      "             MISC: precision:  64.11%; recall:  42.28%; FB1:  50.95\n",
      "              ORG: precision:  48.67%; recall:  39.89%; FB1:  43.84\n",
      "              PER: precision:  61.79%; recall:  55.17%; FB1:  58.30\n",
      "\n",
      "epoch = 11\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4121 phrases; correct: 2380.\n",
      "accuracy:  93.62%; precision:  57.75%; recall:  49.24%; FB1:  53.16\n",
      "              LOC: precision:  54.30%; recall:  66.30%; FB1:  59.70\n",
      "             MISC: precision:  68.47%; recall:  42.57%; FB1:  52.50\n",
      "              ORG: precision:  51.93%; recall:  37.95%; FB1:  43.85\n",
      "              PER: precision:  60.84%; recall:  49.68%; FB1:  54.70\n",
      "\n",
      "epoch = 12\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4127 phrases; correct: 2315.\n",
      "accuracy:  93.50%; precision:  56.09%; recall:  47.90%; FB1:  51.67\n",
      "              LOC: precision:  52.55%; recall:  66.22%; FB1:  58.60\n",
      "             MISC: precision:  73.00%; recall:  41.49%; FB1:  52.90\n",
      "              ORG: precision:  47.12%; recall:  34.89%; FB1:  40.09\n",
      "              PER: precision:  59.42%; recall:  48.61%; FB1:  53.47\n",
      "\n",
      "epoch = 13\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3509 phrases; correct: 2101.\n",
      "accuracy:  93.25%; precision:  59.87%; recall:  43.47%; FB1:  50.37\n",
      "              LOC: precision:  61.30%; recall:  57.41%; FB1:  59.29\n",
      "             MISC: precision:  69.00%; recall:  37.03%; FB1:  48.20\n",
      "              ORG: precision:  54.03%; recall:  35.13%; FB1:  42.58\n",
      "              PER: precision:  58.16%; recall:  43.75%; FB1:  49.94\n",
      "\n",
      "epoch = 14\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3932 phrases; correct: 2249.\n",
      "accuracy:  93.40%; precision:  57.20%; recall:  46.53%; FB1:  51.32\n",
      "              LOC: precision:  53.03%; recall:  66.05%; FB1:  58.82\n",
      "             MISC: precision:  75.57%; recall:  32.77%; FB1:  45.72\n",
      "              ORG: precision:  52.81%; recall:  40.93%; FB1:  46.12\n",
      "              PER: precision:  59.38%; recall:  44.97%; FB1:  51.18\n",
      "\n",
      "epoch = 15\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4131 phrases; correct: 2430.\n",
      "accuracy:  93.75%; precision:  58.82%; recall:  50.28%; FB1:  54.22\n",
      "              LOC: precision:  57.28%; recall:  63.93%; FB1:  60.42\n",
      "             MISC: precision:  69.20%; recall:  39.60%; FB1:  50.38\n",
      "              ORG: precision:  52.28%; recall:  39.73%; FB1:  45.15\n",
      "              PER: precision:  60.53%; recall:  55.82%; FB1:  58.08\n",
      "\n",
      "epoch = 16\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3870 phrases; correct: 2374.\n",
      "accuracy:  93.75%; precision:  61.34%; recall:  49.12%; FB1:  54.56\n",
      "              LOC: precision:  63.81%; recall:  60.46%; FB1:  62.09\n",
      "             MISC: precision:  70.31%; recall:  40.10%; FB1:  51.07\n",
      "              ORG: precision:  54.17%; recall:  40.85%; FB1:  46.58\n",
      "              PER: precision:  60.37%; recall:  53.39%; FB1:  56.67\n",
      "\n",
      "epoch = 17\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4064 phrases; correct: 2483.\n",
      "accuracy:  93.90%; precision:  61.10%; recall:  51.38%; FB1:  55.82\n",
      "              LOC: precision:  60.88%; recall:  63.00%; FB1:  61.92\n",
      "             MISC: precision:  70.39%; recall:  41.19%; FB1:  51.97\n",
      "              ORG: precision:  56.08%; recall:  44.24%; FB1:  49.46\n",
      "              PER: precision:  60.85%; recall:  55.25%; FB1:  57.91\n",
      "\n",
      "epoch = 18\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3764 phrases; correct: 2297.\n",
      "accuracy:  93.59%; precision:  61.03%; recall:  47.53%; FB1:  53.44\n",
      "              LOC: precision:  60.58%; recall:  63.51%; FB1:  62.01\n",
      "             MISC: precision:  72.40%; recall:  35.84%; FB1:  47.95\n",
      "              ORG: precision:  56.81%; recall:  41.66%; FB1:  48.07\n",
      "              PER: precision:  59.86%; recall:  47.68%; FB1:  53.08\n",
      "\n",
      "epoch = 19\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3996 phrases; correct: 2414.\n",
      "accuracy:  93.82%; precision:  60.41%; recall:  49.95%; FB1:  54.68\n",
      "              LOC: precision:  61.30%; recall:  61.30%; FB1:  61.30\n",
      "             MISC: precision:  71.46%; recall:  36.93%; FB1:  48.69\n",
      "              ORG: precision:  53.67%; recall:  45.93%; FB1:  49.50\n",
      "              PER: precision:  60.68%; recall:  53.32%; FB1:  56.76\n",
      "\n",
      "epoch = 20\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3873 phrases; correct: 2294.\n",
      "accuracy:  93.51%; precision:  59.23%; recall:  47.47%; FB1:  52.70\n",
      "              LOC: precision:  55.46%; recall:  66.64%; FB1:  60.54\n",
      "             MISC: precision:  68.26%; recall:  39.60%; FB1:  50.13\n",
      "              ORG: precision:  55.35%; recall:  36.26%; FB1:  43.82\n",
      "              PER: precision:  62.27%; recall:  46.90%; FB1:  53.50\n",
      "\n",
      "epoch = 21\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3629 phrases; correct: 2247.\n",
      "accuracy:  93.53%; precision:  61.92%; recall:  46.49%; FB1:  53.11\n",
      "              LOC: precision:  61.88%; recall:  61.98%; FB1:  61.93\n",
      "             MISC: precision:  76.68%; recall:  38.42%; FB1:  51.19\n",
      "              ORG: precision:  54.33%; recall:  37.95%; FB1:  44.69\n",
      "              PER: precision:  61.14%; recall:  46.82%; FB1:  53.03\n",
      "\n",
      "epoch = 22\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3824 phrases; correct: 2385.\n",
      "accuracy:  93.81%; precision:  62.37%; recall:  49.35%; FB1:  55.10\n",
      "              LOC: precision:  64.42%; recall:  62.40%; FB1:  63.40\n",
      "             MISC: precision:  69.48%; recall:  43.96%; FB1:  53.85\n",
      "              ORG: precision:  56.14%; recall:  41.98%; FB1:  48.04\n",
      "              PER: precision:  61.37%; recall:  48.75%; FB1:  54.34\n",
      "\n",
      "epoch = 23\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4110 phrases; correct: 2447.\n",
      "accuracy:  93.81%; precision:  59.54%; recall:  50.63%; FB1:  54.72\n",
      "              LOC: precision:  54.71%; recall:  68.33%; FB1:  60.77\n",
      "             MISC: precision:  74.76%; recall:  39.01%; FB1:  51.27\n",
      "              ORG: precision:  55.10%; recall:  42.22%; FB1:  47.81\n",
      "              PER: precision:  62.40%; recall:  51.53%; FB1:  56.45\n",
      "\n",
      "epoch = 24\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4026 phrases; correct: 2450.\n",
      "accuracy:  93.77%; precision:  60.85%; recall:  50.69%; FB1:  55.31\n",
      "              LOC: precision:  57.12%; recall:  65.88%; FB1:  61.19\n",
      "             MISC: precision:  67.07%; recall:  49.01%; FB1:  56.64\n",
      "              ORG: precision:  58.42%; recall:  38.84%; FB1:  46.66\n",
      "              PER: precision:  63.12%; recall:  49.61%; FB1:  55.56\n",
      "\n",
      "epoch = 25\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3886 phrases; correct: 2415.\n",
      "accuracy:  93.88%; precision:  62.15%; recall:  49.97%; FB1:  55.40\n",
      "              LOC: precision:  65.15%; recall:  61.90%; FB1:  63.48\n",
      "             MISC: precision:  70.23%; recall:  39.70%; FB1:  50.73\n",
      "              ORG: precision:  53.76%; recall:  44.96%; FB1:  48.97\n",
      "              PER: precision:  62.77%; recall:  51.75%; FB1:  56.73\n",
      "\n",
      "epoch = 26\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3825 phrases; correct: 2324.\n",
      "accuracy:  93.61%; precision:  60.76%; recall:  48.09%; FB1:  53.68\n",
      "              LOC: precision:  57.68%; recall:  67.06%; FB1:  62.02\n",
      "             MISC: precision:  72.55%; recall:  35.84%; FB1:  47.98\n",
      "              ORG: precision:  56.64%; recall:  40.53%; FB1:  47.25\n",
      "              PER: precision:  62.63%; recall:  47.61%; FB1:  54.10\n",
      "\n",
      "epoch = 27\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3611 phrases; correct: 2207.\n",
      "accuracy:  93.50%; precision:  61.12%; recall:  45.67%; FB1:  52.27\n",
      "              LOC: precision:  60.64%; recall:  64.18%; FB1:  62.36\n",
      "             MISC: precision:  74.04%; recall:  32.48%; FB1:  45.15\n",
      "              ORG: precision:  54.32%; recall:  42.55%; FB1:  47.72\n",
      "              PER: precision:  62.68%; recall:  42.33%; FB1:  50.53\n",
      "\n",
      "epoch = 28\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3870 phrases; correct: 2327.\n",
      "accuracy:  93.65%; precision:  60.13%; recall:  48.15%; FB1:  53.48\n",
      "              LOC: precision:  58.36%; recall:  66.81%; FB1:  62.30\n",
      "             MISC: precision:  67.69%; recall:  41.49%; FB1:  51.44\n",
      "              ORG: precision:  54.71%; recall:  40.21%; FB1:  46.35\n",
      "              PER: precision:  62.82%; recall:  44.25%; FB1:  51.93\n",
      "\n",
      "epoch = 29\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3623 phrases; correct: 2189.\n",
      "accuracy:  93.44%; precision:  60.42%; recall:  45.29%; FB1:  51.77\n",
      "              LOC: precision:  57.60%; recall:  66.72%; FB1:  61.83\n",
      "             MISC: precision:  76.28%; recall:  30.89%; FB1:  43.97\n",
      "              ORG: precision:  54.97%; recall:  41.02%; FB1:  46.98\n",
      "              PER: precision:  63.04%; recall:  41.40%; FB1:  49.98\n",
      "\n",
      "epoch = 30\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4197 phrases; correct: 2423.\n",
      "accuracy:  93.68%; precision:  57.73%; recall:  50.13%; FB1:  53.67\n",
      "              LOC: precision:  53.74%; recall:  68.16%; FB1:  60.10\n",
      "             MISC: precision:  67.38%; recall:  37.43%; FB1:  48.12\n",
      "              ORG: precision:  53.44%; recall:  44.48%; FB1:  48.55\n",
      "              PER: precision:  62.26%; recall:  49.11%; FB1:  54.91\n",
      "\n",
      "epoch = 31\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3649 phrases; correct: 2260.\n",
      "accuracy:  93.55%; precision:  61.93%; recall:  46.76%; FB1:  53.29\n",
      "              LOC: precision:  61.53%; recall:  62.83%; FB1:  62.17\n",
      "             MISC: precision:  75.33%; recall:  34.16%; FB1:  47.00\n",
      "              ORG: precision:  55.88%; recall:  43.27%; FB1:  48.77\n",
      "              PER: precision:  62.11%; recall:  45.40%; FB1:  52.45\n",
      "\n",
      "epoch = 32\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3689 phrases; correct: 2347.\n",
      "accuracy:  93.83%; precision:  63.62%; recall:  48.56%; FB1:  55.08\n",
      "              LOC: precision:  62.37%; recall:  63.84%; FB1:  63.10\n",
      "             MISC: precision:  75.29%; recall:  38.61%; FB1:  51.05\n",
      "              ORG: precision:  59.60%; recall:  43.27%; FB1:  50.14\n",
      "              PER: precision:  62.77%; recall:  47.54%; FB1:  54.10\n",
      "\n",
      "epoch = 33\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3963 phrases; correct: 2412.\n",
      "accuracy:  93.79%; precision:  60.86%; recall:  49.91%; FB1:  54.84\n",
      "              LOC: precision:  60.62%; recall:  65.03%; FB1:  62.75\n",
      "             MISC: precision:  75.28%; recall:  33.47%; FB1:  46.33\n",
      "              ORG: precision:  54.91%; recall:  41.90%; FB1:  47.53\n",
      "              PER: precision:  60.46%; recall:  56.10%; FB1:  58.20\n",
      "\n",
      "epoch = 34\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3647 phrases; correct: 2308.\n",
      "accuracy:  93.72%; precision:  63.28%; recall:  47.76%; FB1:  54.43\n",
      "              LOC: precision:  61.62%; recall:  65.79%; FB1:  63.64\n",
      "             MISC: precision:  74.38%; recall:  38.51%; FB1:  50.75\n",
      "              ORG: precision:  58.97%; recall:  40.53%; FB1:  48.04\n",
      "              PER: precision:  63.27%; recall:  45.61%; FB1:  53.01\n",
      "\n",
      "epoch = 35\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3718 phrases; correct: 2288.\n",
      "accuracy:  93.60%; precision:  61.54%; recall:  47.34%; FB1:  53.51\n",
      "              LOC: precision:  61.15%; recall:  64.10%; FB1:  62.59\n",
      "             MISC: precision:  69.51%; recall:  39.50%; FB1:  50.38\n",
      "              ORG: precision:  58.33%; recall:  37.79%; FB1:  45.87\n",
      "              PER: precision:  60.16%; recall:  47.32%; FB1:  52.98\n",
      "\n",
      "epoch = 36\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3833 phrases; correct: 2355.\n",
      "accuracy:  93.70%; precision:  61.44%; recall:  48.73%; FB1:  54.35\n",
      "              LOC: precision:  58.00%; recall:  67.82%; FB1:  62.53\n",
      "             MISC: precision:  73.24%; recall:  40.10%; FB1:  51.82\n",
      "              ORG: precision:  56.95%; recall:  40.29%; FB1:  47.19\n",
      "              PER: precision:  63.57%; recall:  46.32%; FB1:  53.59\n",
      "\n",
      "epoch = 37\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3786 phrases; correct: 2355.\n",
      "accuracy:  93.74%; precision:  62.20%; recall:  48.73%; FB1:  54.65\n",
      "              LOC: precision:  60.03%; recall:  63.84%; FB1:  61.88\n",
      "             MISC: precision:  76.39%; recall:  40.69%; FB1:  53.10\n",
      "              ORG: precision:  56.27%; recall:  44.48%; FB1:  49.68\n",
      "              PER: precision:  63.11%; recall:  45.54%; FB1:  52.90\n",
      "\n",
      "epoch = 38\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3772 phrases; correct: 2386.\n",
      "accuracy:  93.84%; precision:  63.26%; recall:  49.37%; FB1:  55.46\n",
      "              LOC: precision:  65.81%; recall:  62.57%; FB1:  64.15\n",
      "             MISC: precision:  80.13%; recall:  36.73%; FB1:  50.37\n",
      "              ORG: precision:  54.73%; recall:  48.03%; FB1:  51.16\n",
      "              PER: precision:  61.99%; recall:  48.54%; FB1:  54.44\n",
      "\n",
      "epoch = 39\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3656 phrases; correct: 2299.\n",
      "accuracy:  93.63%; precision:  62.88%; recall:  47.57%; FB1:  54.16\n",
      "              LOC: precision:  63.81%; recall:  61.22%; FB1:  62.49\n",
      "             MISC: precision:  75.40%; recall:  37.62%; FB1:  50.20\n",
      "              ORG: precision:  56.62%; recall:  38.28%; FB1:  45.67\n",
      "              PER: precision:  61.10%; recall:  51.46%; FB1:  55.87\n",
      "\n",
      "epoch = 40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c3ac09706ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mword_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmm_viterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mw_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mw_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e0bc6ef1d1db>\u001b[0m in \u001b[0;36mhmm_viterbi\u001b[0;34m(W, words)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattribs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mscore_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W = {}\n",
    "epoch = 100\n",
    "for e in range(epoch):\n",
    "    print('epoch = '+ str(e+1))\n",
    "    # training\n",
    "    for sentence in text_train:\n",
    "\n",
    "        words = [s[0] for s in sentence]\n",
    "        word_tags = [s[-1] for s in sentence]\n",
    "\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "        w_true = create_features(words, word_tags)\n",
    "        w_pred = create_features(words, y_pred)\n",
    "        for wt in w_true:\n",
    "            if wt in W: W[wt] += w_true[wt]\n",
    "            else: W[wt] = w_true[wt]\n",
    "\n",
    "        for wp in w_pred:\n",
    "            if wp in W: W[wp] -= w_pred[wp]\n",
    "            else: W[wp] = -w_pred[wp]\n",
    "                \n",
    "    # predicting            \n",
    "    filename = 'result_SPViterbi.txt'\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    save_wt = '\\n'\n",
    "    for sentence in text_pred:\n",
    "        words = [s[0] for s in sentence]\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "\n",
    "        for wt in range(len(sentence)):\n",
    "            save_wt += sentence[wt][0]+' '+sentence[wt][1]+' '+sentence[wt][2]+' '+sentence[wt][3]+' '+sentence[wt][4]+' '+y_pred[wt]+'\\n'\n",
    "\n",
    "        save_wt += '\\n'\n",
    "\n",
    "    with open('result_SPViterbi.txt', 'w+') as txt_file:\n",
    "        txt_file.write(save_wt)\n",
    "\n",
    "    output = subprocess.run(\"/usr/bin/perl -w conlleval < result_SPViterbi.txt\", shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "    print('\\n'+output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

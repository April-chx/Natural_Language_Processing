{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'MO', 'O']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [t.strip().split(' ')[-1] for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- O\\n',open(\"../data/conll03/eng.train\").readlines())) if len(t.strip().split(' '))>1]\n",
    "tags = sorted(list(set(tags)))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hmm_viterbi(W, words):\n",
    "    y_pred = []\n",
    "    for num in range(len(words)):\n",
    "        if num == 0:\n",
    "            best_score = [W[('*', t)] if ('*',t) in W else 0 for t in tags]\n",
    "            best_score = [best_score[s]+W[(words[num], tags[s])] if (words[num], tags[s]) in W else best_score[s] for s in range(len(best_score))]\n",
    "            y_pred.append(tags[best_score.index(max(best_score))])\n",
    "        else:\n",
    "            sum_score = [np.array(best_score) for t in tags]\n",
    "            for t_next in range(len(sum_score)):\n",
    "                sum_score[t_next] = [W[(tags[t_prev],tags[t_next])]+sum_score[t_next][t_prev] if (tags[t_prev],tags[t_next]) in W \n",
    "                                     else sum_score[t_next][t_prev]\n",
    "                                     for t_prev in range(len(sum_score[t_next]))]\n",
    "            sum_score = [np.array(sum_score[s])+W[(words[num], tags[s])] if (words[num], tags[s]) in W else np.array(sum_score[s]) for s in range(len(sum_score))]\n",
    "            best_score = [max(s) for s in sum_score]\n",
    "            y_pred.append(tags[best_score.index(max(best_score))])\n",
    "    return y_pred\n",
    "\n",
    "def create_features(words, tags):\n",
    "    temp_dict = {}\n",
    "    for t in range(len(tags)+1):\n",
    "        if t == 0: prev_tag = '*'\n",
    "        else: prev_tag = tags[t-1]\n",
    "        if t == len(tags): next_tag = '*'\n",
    "        else: next_tag = tags[t]\n",
    "        \n",
    "        if (prev_tag, next_tag) in temp_dict:\n",
    "            temp_dict[(prev_tag, next_tag)] += 0.01\n",
    "        else: temp_dict[(prev_tag, next_tag)] = 0.01\n",
    "        \n",
    "    for t in range(len(tags)):\n",
    "        if (words[t], tags[t]) in temp_dict:\n",
    "            temp_dict[(words[t], tags[t])] += 1\n",
    "        else: temp_dict[(words[t], tags[t])] = 1\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['EU', 'NNP', 'I-NP', 'I-ORG'],\n",
       "  ['rejects', 'VBZ', 'I-VP', 'O'],\n",
       "  ['German', 'JJ', 'I-NP', 'I-MISC'],\n",
       "  ['call', 'NN', 'I-NP', 'O'],\n",
       "  ['to', 'TO', 'I-VP', 'O'],\n",
       "  ['boycott', 'VB', 'I-VP', 'O'],\n",
       "  ['British', 'JJ', 'I-NP', 'I-MISC'],\n",
       "  ['lamb', 'NN', 'I-NP', 'O'],\n",
       "  ['.', '.', 'O', 'O']]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- O\\n',open(\"../data/conll03/eng.train\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_train = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['CRICKET', 'NNP', 'I-NP', 'O'],\n",
       "  ['-', ':', 'O', 'O'],\n",
       "  ['LEICESTERSHIRE', 'NNP', 'I-NP', 'I-ORG'],\n",
       "  ['TAKE', 'NNP', 'I-NP', 'O'],\n",
       "  ['OVER', 'IN', 'I-PP', 'O'],\n",
       "  ['AT', 'NNP', 'I-NP', 'O'],\n",
       "  ['TOP', 'NNP', 'I-NP', 'O'],\n",
       "  ['AFTER', 'NNP', 'I-NP', 'O'],\n",
       "  ['INNINGS', 'NNP', 'I-NP', 'O'],\n",
       "  ['VICTORY', 'NN', 'I-NP', 'O'],\n",
       "  ['.', '.', 'O', 'O']]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- O\\n',open(\"../data/conll03/eng.testa\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_pred = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_pred[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5626 phrases; correct: 3718.\n",
      "accuracy:  92.98%; precision:  66.09%; recall:  62.57%; FB1:  64.28\n",
      "              LOC: precision:  81.54%; recall:  80.57%; FB1:  81.05\n",
      "             MISC: precision:  52.02%; recall:  53.04%; FB1:  52.52\n",
      "              ORG: precision:  48.09%; recall:  45.04%; FB1:  46.52\n",
      "              PER: precision:  70.90%; recall:  62.16%; FB1:  66.24\n",
      "\n",
      "epoch = 2\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5344 phrases; correct: 3571.\n",
      "accuracy:  92.72%; precision:  66.82%; recall:  60.10%; FB1:  63.28\n",
      "              LOC: precision:  79.89%; recall:  77.41%; FB1:  78.63\n",
      "             MISC: precision:  62.62%; recall:  56.51%; FB1:  59.41\n",
      "              ORG: precision:  42.26%; recall:  42.36%; FB1:  42.31\n",
      "              PER: precision:  76.37%; recall:  57.55%; FB1:  65.63\n",
      "\n",
      "epoch = 3\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5382 phrases; correct: 3365.\n",
      "accuracy:  92.53%; precision:  62.52%; recall:  56.63%; FB1:  59.43\n",
      "              LOC: precision:  67.90%; recall:  68.05%; FB1:  67.97\n",
      "             MISC: precision:  60.83%; recall:  58.79%; FB1:  59.79\n",
      "              ORG: precision:  49.68%; recall:  46.09%; FB1:  47.81\n",
      "              PER: precision:  67.92%; recall:  51.85%; FB1:  58.81\n",
      "\n",
      "epoch = 4\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5314 phrases; correct: 3328.\n",
      "accuracy:  92.52%; precision:  62.63%; recall:  56.01%; FB1:  59.13\n",
      "              LOC: precision:  71.03%; recall:  67.94%; FB1:  69.45\n",
      "             MISC: precision:  57.38%; recall:  56.07%; FB1:  56.72\n",
      "              ORG: precision:  49.38%; recall:  44.22%; FB1:  46.66\n",
      "              PER: precision:  66.67%; recall:  52.66%; FB1:  58.84\n",
      "\n",
      "epoch = 5\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5413 phrases; correct: 3136.\n",
      "accuracy:  91.59%; precision:  57.93%; recall:  52.78%; FB1:  55.24\n",
      "              LOC: precision:  63.78%; recall:  65.27%; FB1:  64.51\n",
      "             MISC: precision:  53.75%; recall:  55.21%; FB1:  54.47\n",
      "              ORG: precision:  40.94%; recall:  38.26%; FB1:  39.55\n",
      "              PER: precision:  68.64%; recall:  49.67%; FB1:  57.64\n",
      "\n",
      "epoch = 6\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5358 phrases; correct: 3114.\n",
      "accuracy:  91.63%; precision:  58.12%; recall:  52.41%; FB1:  55.12\n",
      "              LOC: precision:  59.13%; recall:  62.60%; FB1:  60.81\n",
      "             MISC: precision:  55.75%; recall:  51.52%; FB1:  53.55\n",
      "              ORG: precision:  47.61%; recall:  43.85%; FB1:  45.65\n",
      "              PER: precision:  67.95%; recall:  48.91%; FB1:  56.88\n",
      "\n",
      "epoch = 7\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5598 phrases; correct: 3210.\n",
      "accuracy:  91.55%; precision:  57.34%; recall:  54.02%; FB1:  55.63\n",
      "              LOC: precision:  61.08%; recall:  67.83%; FB1:  64.28\n",
      "             MISC: precision:  58.66%; recall:  52.17%; FB1:  55.22\n",
      "              ORG: precision:  42.45%; recall:  44.00%; FB1:  43.21\n",
      "              PER: precision:  66.25%; recall:  48.48%; FB1:  55.99\n",
      "\n",
      "epoch = 8\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5552 phrases; correct: 3038.\n",
      "accuracy:  90.82%; precision:  54.72%; recall:  51.13%; FB1:  52.86\n",
      "              LOC: precision:  57.79%; recall:  67.01%; FB1:  62.06\n",
      "             MISC: precision:  61.34%; recall:  51.63%; FB1:  56.07\n",
      "              ORG: precision:  38.36%; recall:  41.16%; FB1:  39.71\n",
      "              PER: precision:  64.54%; recall:  42.29%; FB1:  51.10\n",
      "\n",
      "epoch = 9\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5683 phrases; correct: 3110.\n",
      "accuracy:  90.77%; precision:  54.72%; recall:  52.34%; FB1:  53.51\n",
      "              LOC: precision:  56.18%; recall:  65.05%; FB1:  60.29\n",
      "             MISC: precision:  49.19%; recall:  49.46%; FB1:  49.32\n",
      "              ORG: precision:  40.27%; recall:  39.82%; FB1:  40.04\n",
      "              PER: precision:  70.99%; recall:  50.22%; FB1:  58.82\n",
      "\n",
      "epoch = 10\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5412 phrases; correct: 3096.\n",
      "accuracy:  91.23%; precision:  57.21%; recall:  52.10%; FB1:  54.54\n",
      "              LOC: precision:  63.13%; recall:  67.94%; FB1:  65.44\n",
      "             MISC: precision:  60.52%; recall:  53.04%; FB1:  56.53\n",
      "              ORG: precision:  40.90%; recall:  44.22%; FB1:  42.49\n",
      "              PER: precision:  65.08%; recall:  41.59%; FB1:  50.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W = {}\n",
    "epoch = 10\n",
    "for e in range(epoch):\n",
    "    print('epoch = '+ str(e+1))\n",
    "    \n",
    "    for sentence in text_train:\n",
    "\n",
    "        words = [s[0] for s in sentence]\n",
    "        word_tags = [s[-1] for s in sentence]\n",
    "\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "        w_true = create_features(words, word_tags)\n",
    "        w_pred = create_features(words, y_pred)\n",
    "\n",
    "        for wt in w_true:\n",
    "            if wt in W: W[wt] += w_true[wt]\n",
    "            else: W[wt] = w_true[wt]\n",
    "\n",
    "        for wp in w_pred:\n",
    "            if wp in W: W[wp] -= w_pred[wp]\n",
    "            else: W[wp] = -w_pred[wp]\n",
    "                \n",
    "    filename = 'result_SPViterbi_eng.txt'\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    save_wt = '\\n'\n",
    "    for sentence in text_pred:\n",
    "        words = [s[0] for s in sentence]\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "\n",
    "        for wt in range(len(sentence)):\n",
    "            save_wt += sentence[wt][0]+' '+sentence[wt][1]+' '+sentence[wt][2]+' '+sentence[wt][3]+' '+y_pred[wt]+'\\n'\n",
    "\n",
    "        save_wt += '\\n'\n",
    "\n",
    "    with open('result_SPViterbi_eng.txt', 'w+') as txt_file:\n",
    "        txt_file.write(save_wt)\n",
    "\n",
    "    output = subprocess.run(\"/usr/bin/perl -w conlleval < result_SPViterbi_eng.txt\", shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "    print('\\n'+output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

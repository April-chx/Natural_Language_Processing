{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [t.strip().split(' ')[-1] for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- -X- O\\n',open(\"../data/conll03/deu.train\", encoding=\"ISO-8859-1\").readlines())) if len(t.strip().split(' '))>1]\n",
    "tags = sorted(list(set(tags)))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hmm_viterbi(W, words):\n",
    "    y_pred = []\n",
    "    for num in range(len(words)):\n",
    "        if num == 0:\n",
    "            best_score = [W[('*', t)] if ('*',t) in W else 0 for t in tags]\n",
    "            best_score = [best_score[s]+W[(words[num], tags[s])] if (words[num], tags[s]) in W else best_score[s] for s in range(len(best_score))]\n",
    "            y_pred.append(tags[best_score.index(max(best_score))])\n",
    "        else:\n",
    "            sum_score = [np.array(best_score) for t in tags]\n",
    "            for t_next in range(len(sum_score)):\n",
    "                sum_score[t_next] = [W[(tags[t_prev],tags[t_next])]+sum_score[t_next][t_prev] if (tags[t_prev],tags[t_next]) in W \n",
    "                                     else sum_score[t_next][t_prev]\n",
    "                                     for t_prev in range(len(sum_score[t_next]))]\n",
    "            sum_score = [np.array(sum_score[s])+W[(words[num], tags[s])] if (words[num], tags[s]) in W else np.array(sum_score[s]) for s in range(len(sum_score))]\n",
    "            best_score = [max(s) for s in sum_score]\n",
    "            y_pred.append(tags[best_score.index(max(best_score))])\n",
    "    return y_pred\n",
    "\n",
    "def create_features(words, tags):\n",
    "    temp_dict = {}\n",
    "    for t in range(len(tags)+1):\n",
    "        if t == 0: prev_tag = '*'\n",
    "        else: prev_tag = tags[t-1]\n",
    "        if t == len(tags): next_tag = '*'\n",
    "        else: next_tag = tags[t]\n",
    "        \n",
    "        if (prev_tag, next_tag) in temp_dict:\n",
    "            temp_dict[(prev_tag, next_tag)] += 0.01\n",
    "        else: temp_dict[(prev_tag, next_tag)] = 0.01\n",
    "        \n",
    "    for t in range(len(tags)):\n",
    "        if (words[t], tags[t]) in temp_dict:\n",
    "            temp_dict[(words[t], tags[t])] += 1\n",
    "        else: temp_dict[(words[t], tags[t])] = 1\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Ereignis', 'Ereignis', 'NN', 'I-NC', 'O'],\n",
       "  ['und', 'und', 'KON', 'O', 'O'],\n",
       "  ['Erzählung', 'Erzählung', 'NN', 'I-NC', 'O'],\n",
       "  ['oder', 'oder', 'KON', 'I-NC', 'O'],\n",
       "  [':', ':', '$.', 'O', 'O']]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- -X- O\\n',open(\"../data/conll03/deu.train\", encoding=\"ISO-8859-1\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_train = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Großer', 'Große', 'NN', 'I-NC', 'O'],\n",
       "  ['Foto-Wettbeweb', '<unknown>', 'NN', 'I-NC', 'O'],\n",
       "  ['\"', '\"', '$(', 'O', 'O'],\n",
       "  ['Nordendler', '<unknown>', 'NN', 'I-NC', 'I-ORG'],\n",
       "  ['\"', '\"', '$(', 'O', 'O'],\n",
       "  ['laden', 'laden', 'VVFIN', 'I-VC', 'O'],\n",
       "  ['die', 'd', 'ART', 'I-NC', 'O'],\n",
       "  ['Nordendler', '<unknown>', 'NN', 'I-NC', 'I-MISC'],\n",
       "  ['ein', 'ein', 'ART', 'B-NC', 'O']]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- -X- O\\n',open(\"../data/conll03/deu.testa\", encoding=\"ISO-8859-1\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_pred = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_pred[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2810 phrases; correct: 1318.\n",
      "accuracy:  90.44%; precision:  46.90%; recall:  27.27%; FB1:  34.49\n",
      "              LOC: precision:  52.73%; recall:  41.74%; FB1:  46.60\n",
      "             MISC: precision:  33.40%; recall:  15.45%; FB1:  21.12\n",
      "              ORG: precision:  33.53%; recall:  23.21%; FB1:  27.43\n",
      "              PER: precision:  69.40%; recall:  27.19%; FB1:  39.08\n",
      "\n",
      "epoch = 2\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2477 phrases; correct: 1325.\n",
      "accuracy:  90.91%; precision:  53.49%; recall:  27.42%; FB1:  36.25\n",
      "              LOC: precision:  58.65%; recall:  36.75%; FB1:  45.18\n",
      "             MISC: precision:  36.98%; recall:  16.73%; FB1:  23.04\n",
      "              ORG: precision:  43.40%; recall:  27.56%; FB1:  33.71\n",
      "              PER: precision:  77.24%; recall:  27.12%; FB1:  40.15\n",
      "\n",
      "epoch = 3\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2768 phrases; correct: 1271.\n",
      "accuracy:  90.05%; precision:  45.92%; recall:  26.30%; FB1:  33.44\n",
      "              LOC: precision:  55.82%; recall:  34.12%; FB1:  42.35\n",
      "             MISC: precision:  31.53%; recall:  15.54%; FB1:  20.82\n",
      "              ORG: precision:  31.74%; recall:  26.27%; FB1:  28.75\n",
      "              PER: precision:  73.90%; recall:  27.48%; FB1:  40.06\n",
      "\n",
      "epoch = 4\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2586 phrases; correct: 1263.\n",
      "accuracy:  90.30%; precision:  48.84%; recall:  26.13%; FB1:  34.05\n",
      "              LOC: precision:  60.42%; recall:  38.78%; FB1:  47.24\n",
      "             MISC: precision:  37.89%; recall:  17.03%; FB1:  23.50\n",
      "              ORG: precision:  35.02%; recall:  26.19%; FB1:  29.97\n",
      "              PER: precision:  69.06%; recall:  21.98%; FB1:  33.35\n",
      "\n",
      "epoch = 5\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2682 phrases; correct: 1164.\n",
      "accuracy:  89.63%; precision:  43.40%; recall:  24.08%; FB1:  30.98\n",
      "              LOC: precision:  49.10%; recall:  27.86%; FB1:  35.55\n",
      "             MISC: precision:  39.63%; recall:  17.03%; FB1:  23.82\n",
      "              ORG: precision:  30.34%; recall:  27.80%; FB1:  29.02\n",
      "              PER: precision:  72.11%; recall:  22.70%; FB1:  34.53\n",
      "\n",
      "epoch = 6\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2923 phrases; correct: 1210.\n",
      "accuracy:  89.32%; precision:  41.40%; recall:  25.04%; FB1:  31.20\n",
      "              LOC: precision:  52.22%; recall:  29.89%; FB1:  38.02\n",
      "             MISC: precision:  28.02%; recall:  18.12%; FB1:  22.01\n",
      "              ORG: precision:  30.29%; recall:  26.99%; FB1:  28.55\n",
      "              PER: precision:  69.47%; recall:  24.20%; FB1:  35.89\n",
      "\n",
      "epoch = 7\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3143 phrases; correct: 1237.\n",
      "accuracy:  88.88%; precision:  39.36%; recall:  25.59%; FB1:  31.02\n",
      "              LOC: precision:  49.50%; recall:  33.87%; FB1:  40.22\n",
      "             MISC: precision:  32.78%; recall:  17.52%; FB1:  22.84\n",
      "              ORG: precision:  24.53%; recall:  26.19%; FB1:  25.33\n",
      "              PER: precision:  71.28%; recall:  23.91%; FB1:  35.81\n",
      "\n",
      "epoch = 8\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2907 phrases; correct: 1224.\n",
      "accuracy:  89.27%; precision:  42.11%; recall:  25.33%; FB1:  31.63\n",
      "              LOC: precision:  58.18%; recall:  34.63%; FB1:  43.42\n",
      "             MISC: precision:  37.74%; recall:  17.23%; FB1:  23.66\n",
      "              ORG: precision:  25.31%; recall:  26.35%; FB1:  25.82\n",
      "              PER: precision:  69.62%; recall:  22.41%; FB1:  33.91\n",
      "\n",
      "epoch = 9\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3193 phrases; correct: 1211.\n",
      "accuracy:  88.53%; precision:  37.93%; recall:  25.06%; FB1:  30.18\n",
      "              LOC: precision:  52.13%; recall:  33.19%; FB1:  40.56\n",
      "             MISC: precision:  30.76%; recall:  18.12%; FB1:  22.80\n",
      "              ORG: precision:  22.71%; recall:  25.54%; FB1:  24.04\n",
      "              PER: precision:  70.89%; recall:  22.77%; FB1:  34.47\n",
      "\n",
      "epoch = 10\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3169 phrases; correct: 1166.\n",
      "accuracy:  88.36%; precision:  36.79%; recall:  24.13%; FB1:  29.14\n",
      "              LOC: precision:  50.98%; recall:  32.94%; FB1:  40.02\n",
      "             MISC: precision:  21.37%; recall:  13.86%; FB1:  16.82\n",
      "              ORG: precision:  24.39%; recall:  25.71%; FB1:  25.03\n",
      "              PER: precision:  71.78%; recall:  22.70%; FB1:  34.49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W = {}\n",
    "epoch = 10\n",
    "for e in range(epoch):\n",
    "    print('epoch = '+ str(e+1))\n",
    "    \n",
    "    for sentence in text_train:\n",
    "\n",
    "        words = [s[0] for s in sentence]\n",
    "        word_tags = [s[-1] for s in sentence]\n",
    "\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "        w_true = create_features(words, word_tags)\n",
    "        w_pred = create_features(words, y_pred)\n",
    "\n",
    "        for wt in w_true:\n",
    "            if wt in W: W[wt] += w_true[wt]\n",
    "            else: W[wt] = w_true[wt]\n",
    "\n",
    "        for wp in w_pred:\n",
    "            if wp in W: W[wp] -= w_pred[wp]\n",
    "            else: W[wp] = -w_pred[wp]\n",
    "                \n",
    "    filename = 'result_SPViterbi_deu.txt'\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    save_wt = '\\n'\n",
    "    for sentence in text_pred:\n",
    "        words = [s[0] for s in sentence]\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "\n",
    "        for wt in range(len(sentence)):\n",
    "            save_wt += sentence[wt][0]+' '+sentence[wt][1]+' '+sentence[wt][2]+' '+sentence[wt][3]+' '+sentence[wt][4]+' '+y_pred[wt]+'\\n'\n",
    "\n",
    "        save_wt += '\\n'\n",
    "\n",
    "    with open('result_SPViterbi_deu.txt', 'w+') as txt_file:\n",
    "        txt_file.write(save_wt)\n",
    "\n",
    "    output = subprocess.run(\"/usr/bin/perl -w conlleval < result_SPViterbi_deu.txt\", shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "    print('\\n'+output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'MO', 'O']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [t.strip().split(' ')[-1] for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- O\\n',open(\"../data/conll03/eng.train\").readlines())) if len(t.strip().split(' '))>1]\n",
    "tags = sorted(list(set(tags)))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def if_has_W(feature):\n",
    "    if feature not in W:\n",
    "        return 0\n",
    "    else:\n",
    "        return W[feature]\n",
    "\n",
    "\n",
    "def Pre_Next(): # ('NN','NN')\n",
    "    P_tags  =[] \n",
    "    for pt in tags:\n",
    "        tp_P_tags = []\n",
    "        for nt in tags:\n",
    "            tp_P_tags.append(if_has_W(('pt '+nt,'t '+pt)))\n",
    "        P_tags.append(tp_P_tags)\n",
    "    P_tags = np.asarray(P_tags)\n",
    "    return P_tags\n",
    "\n",
    "\n",
    "def hmm_viterbi(W, words):\n",
    "    y_pred = []\n",
    "    i= 0\n",
    "    aug_words = ['__SENTINEL__ O', '__SENTINEL__ O'] + words + ['__SENTINEL__ O', '__SENTINEL__ O']\n",
    "    for ppw_, pw_, w_, nw_, nnw_ in zip(aug_words, aug_words[1:], aug_words[2:], aug_words[3:], aug_words[4:]):\n",
    "        # NOTE: No pt, ppt attribs currently\n",
    "        ppw = ppw_.split(' ')[0]\n",
    "        pw = pw_.split(' ')[0]\n",
    "        w = w_.split(' ')[0]\n",
    "        nw = nw_.split(' ')[0]\n",
    "        nnw = nnw_.split(' ')[0]\n",
    "\n",
    "        ppt = ppw_.split(' ')[1]\n",
    "        pt = pw_.split(' ')[1]\n",
    "        t = w_.split(' ')[1]\n",
    "        nt = nw_.split(' ')[1]\n",
    "        nnt = nnw_.split(' ')[1]\n",
    "\n",
    "\n",
    "        attribs = {'ppw ' + ppw,\n",
    "                   'pw ' + pw,\n",
    "                   'w ' + w,\n",
    "                   'nw ' + nw,\n",
    "                   'nnw ' + nnw,\n",
    "                   'ppt '+ppt,\n",
    "                   'pt '+pt,\n",
    "                   't '+t,\n",
    "                   'nt '+nt,\n",
    "                   'nnt '+nnt\n",
    "                   }\n",
    "\n",
    "        if re.search('[0-9]', w):\n",
    "            attribs.add('dig __NONE__')\n",
    "        if re.search('[A-Z]', w):\n",
    "            attribs.add('uc __NONE__')\n",
    "        if '-' in w:\n",
    "            attribs.add('hyph __NONE__')\n",
    "        \n",
    "        score_list = []\n",
    "        for tag in tags:\n",
    "            score = 0\n",
    "            for a in attribs:\n",
    "                if (a, tag) in W:\n",
    "                    score += W[(a, tag)]\n",
    "            score_list.append(score)\n",
    "        \n",
    "        #Viterbi\n",
    "        if i == 0:\n",
    "            data = words[i]\n",
    "            first_level = []\n",
    "            for tag_number in range(len(tags)):   \n",
    "                first_level.append((if_has_W(('pt '+'','t '+tag))+score_list[tag_number]))\n",
    "            y_pred.append(tags[first_level.index(max(first_level))])\n",
    "            next_value = first_level\n",
    "        else:\n",
    "            data = words[i]\n",
    "            probility = ((next_value + Pre_Next()).T + [score_list[tag_number] for tag_number in range(len(tags))]).T\n",
    "            y_pred.append(tags[probility.max(axis=1).argmax()])\n",
    "            next_value = probility.max(axis=1)\n",
    "\n",
    "        i+=1\n",
    "    return y_pred\n",
    "\n",
    "def create_features(words, word_tags):\n",
    "    loc = 0\n",
    "    w_temp = {}\n",
    "    aug_words = ['__SENTINEL__ O', '__SENTINEL__ O'] + words + ['__SENTINEL__ O', '__SENTINEL__ O']\n",
    "\n",
    "    for ppw_, pw_, w_, nw_, nnw_ in zip(aug_words, aug_words[1:], aug_words[2:], aug_words[3:], aug_words[4:]):\n",
    "        # NOTE: No pt, ppt attribs currently\n",
    "        ppw = ppw_.split(' ')[0]\n",
    "        pw = pw_.split(' ')[0]\n",
    "        w = w_.split(' ')[0]\n",
    "        nw = nw_.split(' ')[0]\n",
    "        nnw = nnw_.split(' ')[0]\n",
    "\n",
    "        ppt = ppw_.split(' ')[1]\n",
    "        pt = pw_.split(' ')[1]\n",
    "        t = w_.split(' ')[1]\n",
    "        nt = nw_.split(' ')[1]\n",
    "        nnt = nnw_.split(' ')[1]\n",
    "\n",
    "\n",
    "        attribs = {'ppw ' + ppw,\n",
    "                   'pw ' + pw,\n",
    "                   'w ' + w,\n",
    "                   'nw ' + nw,\n",
    "                   'nnw ' + nnw\n",
    "                   }\n",
    "\n",
    "        if re.search('[0-9]', w):\n",
    "            attribs.add('dig __NONE__')\n",
    "        if re.search('[A-Z]', w):\n",
    "            attribs.add('uc __NONE__')\n",
    "        if '-' in w:\n",
    "            attribs.add('hyph __NONE__')\n",
    "\n",
    "        for a in attribs:\n",
    "            if (a, word_tags[loc]) in w_temp:\n",
    "                w_temp[(a, word_tags[loc])] += 1\n",
    "            else: w_temp[(a, word_tags[loc])] = 1\n",
    "\n",
    "        attribs = {\n",
    "                   'ppt '+ppt,\n",
    "                   'pt '+pt,\n",
    "                   't '+t,\n",
    "                   'nt '+nt,\n",
    "                   'nnt '+nnt\n",
    "                    }\n",
    "\n",
    "        for a in attribs:\n",
    "            if (a, word_tags[loc]) in w_temp:\n",
    "                w_temp[(a, word_tags[loc])] += 0.01\n",
    "            else: w_temp[(a, word_tags[loc])] = 0.01\n",
    "        loc += 1\n",
    "        \n",
    "        \n",
    "    for i in range(len(word_tags)+1):\n",
    "        if i == 0:\n",
    "            first_tag = 'pt '+''\n",
    "        else:\n",
    "            first_tag = 'pt '+word_tags[i-1]\n",
    "        \n",
    "        if i == len(word_tags):\n",
    "            next_tag = 't '+''\n",
    "        else:\n",
    "            next_tag = 't '+word_tags[i]\n",
    "            \n",
    "            if (first_tag,next_tag) not in w_temp:\n",
    "                w_temp[(first_tag,next_tag)] = 0.001#create_trans((tags[i-1],tags[i]))\n",
    "            else:\n",
    "                w_temp[(first_tag,next_tag)] += 0.001#create_trans((tags[i-1],tags[i]))\n",
    "\n",
    "    return w_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['EU', 'NNP', 'I-NP', 'I-ORG'],\n",
       "  ['rejects', 'VBZ', 'I-VP', 'O'],\n",
       "  ['German', 'JJ', 'I-NP', 'I-MISC'],\n",
       "  ['call', 'NN', 'I-NP', 'O'],\n",
       "  ['to', 'TO', 'I-VP', 'O'],\n",
       "  ['boycott', 'VB', 'I-VP', 'O'],\n",
       "  ['British', 'JJ', 'I-NP', 'I-MISC'],\n",
       "  ['lamb', 'NN', 'I-NP', 'O'],\n",
       "  ['.', '.', 'O', 'O']]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- O\\n',open(\"../data/conll03/eng.train\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_train = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['CRICKET', 'NNP', 'I-NP', 'O'],\n",
       "  ['-', ':', 'O', 'O'],\n",
       "  ['LEICESTERSHIRE', 'NNP', 'I-NP', 'I-ORG'],\n",
       "  ['TAKE', 'NNP', 'I-NP', 'O'],\n",
       "  ['OVER', 'IN', 'I-PP', 'O'],\n",
       "  ['AT', 'NNP', 'I-NP', 'O'],\n",
       "  ['TOP', 'NNP', 'I-NP', 'O'],\n",
       "  ['AFTER', 'NNP', 'I-NP', 'O'],\n",
       "  ['INNINGS', 'NNP', 'I-NP', 'O'],\n",
       "  ['VICTORY', 'NN', 'I-NP', 'O'],\n",
       "  ['.', '.', 'O', 'O']]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- O\\n',open(\"../data/conll03/eng.testa\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_pred = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_pred[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 6898 phrases; correct: 4373.\n",
      "accuracy:  94.96%; precision:  63.40%; recall:  73.59%; FB1:  68.12\n",
      "              LOC: precision:  72.60%; recall:  82.80%; FB1:  77.37\n",
      "             MISC: precision:  57.36%; recall:  71.04%; FB1:  63.47\n",
      "              ORG: precision:  49.91%; recall:  61.07%; FB1:  54.93\n",
      "              PER: precision:  68.22%; recall:  74.81%; FB1:  71.36\n",
      "\n",
      "epoch = 2\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 6885 phrases; correct: 4328.\n",
      "accuracy:  94.93%; precision:  62.86%; recall:  72.84%; FB1:  67.48\n",
      "              LOC: precision:  87.69%; recall:  70.17%; FB1:  77.96\n",
      "             MISC: precision:  73.86%; recall:  66.81%; FB1:  70.16\n",
      "              ORG: precision:  54.19%; recall:  65.62%; FB1:  59.36\n",
      "              PER: precision:  52.18%; recall:  83.77%; FB1:  64.31\n",
      "\n",
      "epoch = 3\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 6256 phrases; correct: 4445.\n",
      "accuracy:  95.87%; precision:  71.05%; recall:  74.81%; FB1:  72.88\n",
      "              LOC: precision:  69.66%; recall:  84.00%; FB1:  76.16\n",
      "             MISC: precision:  71.96%; recall:  75.70%; FB1:  73.78\n",
      "              ORG: precision:  71.66%; recall:  46.38%; FB1:  56.32\n",
      "              PER: precision:  71.81%; recall:  85.88%; FB1:  78.22\n",
      "\n",
      "epoch = 4\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 6002 phrases; correct: 4584.\n",
      "accuracy:  96.48%; precision:  76.37%; recall:  77.15%; FB1:  76.76\n",
      "              LOC: precision:  87.90%; recall:  72.78%; FB1:  79.63\n",
      "             MISC: precision:  76.47%; recall:  77.55%; FB1:  77.01\n",
      "              ORG: precision:  65.10%; recall:  68.16%; FB1:  66.59\n",
      "              PER: precision:  75.54%; recall:  87.84%; FB1:  81.22\n",
      "\n",
      "epoch = 5\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 6022 phrases; correct: 4355.\n",
      "accuracy:  96.04%; precision:  72.32%; recall:  73.29%; FB1:  72.80\n",
      "              LOC: precision:  81.79%; recall:  78.72%; FB1:  80.22\n",
      "             MISC: precision:  82.28%; recall:  75.05%; FB1:  78.50\n",
      "              ORG: precision:  51.57%; recall:  73.38%; FB1:  60.57\n",
      "              PER: precision:  81.93%; recall:  66.94%; FB1:  73.68\n",
      "\n",
      "epoch = 6\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 6208 phrases; correct: 4776.\n",
      "accuracy:  96.79%; precision:  76.93%; recall:  80.38%; FB1:  78.62\n",
      "              LOC: precision:  78.42%; recall:  90.42%; FB1:  83.99\n",
      "             MISC: precision:  80.89%; recall:  75.27%; FB1:  77.98\n",
      "              ORG: precision:  65.31%; recall:  68.23%; FB1:  66.74\n",
      "              PER: precision:  82.25%; recall:  81.76%; FB1:  82.00\n",
      "\n",
      "epoch = 7\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 6122 phrases; correct: 4834.\n",
      "accuracy:  96.88%; precision:  78.96%; recall:  81.35%; FB1:  80.14\n",
      "              LOC: precision:  86.08%; recall:  84.49%; FB1:  85.27\n",
      "             MISC: precision:  76.24%; recall:  76.57%; FB1:  76.41\n",
      "              ORG: precision:  78.01%; recall:  64.28%; FB1:  70.48\n",
      "              PER: precision:  74.91%; recall:  93.05%; FB1:  83.00\n",
      "\n",
      "epoch = 8\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5792 phrases; correct: 4638.\n",
      "accuracy:  96.67%; precision:  80.08%; recall:  78.05%; FB1:  79.05\n",
      "              LOC: precision:  83.60%; recall:  80.19%; FB1:  81.86\n",
      "             MISC: precision:  80.54%; recall:  74.08%; FB1:  77.18\n",
      "              ORG: precision:  72.77%; recall:  64.35%; FB1:  68.30\n",
      "              PER: precision:  81.11%; recall:  87.89%; FB1:  84.37\n",
      "\n",
      "epoch = 9\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 6173 phrases; correct: 4672.\n",
      "accuracy:  96.65%; precision:  75.68%; recall:  78.63%; FB1:  77.13\n",
      "              LOC: precision:  81.84%; recall:  80.95%; FB1:  81.39\n",
      "             MISC: precision:  77.38%; recall:  78.31%; FB1:  77.84\n",
      "              ORG: precision:  58.15%; recall:  76.58%; FB1:  66.11\n",
      "              PER: precision:  86.66%; recall:  77.96%; FB1:  82.08\n",
      "\n",
      "epoch = 10\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5930 phrases; correct: 4675.\n",
      "accuracy:  96.66%; precision:  78.84%; recall:  78.68%; FB1:  78.76\n",
      "              LOC: precision:  87.76%; recall:  79.26%; FB1:  83.30\n",
      "             MISC: precision:  75.71%; recall:  80.80%; FB1:  78.17\n",
      "              ORG: precision:  78.25%; recall:  56.60%; FB1:  65.69\n",
      "              PER: precision:  74.02%; recall:  93.11%; FB1:  82.47\n",
      "\n",
      "epoch = 11\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5656 phrases; correct: 4513.\n",
      "accuracy:  96.44%; precision:  79.79%; recall:  75.95%; FB1:  77.82\n",
      "              LOC: precision:  90.79%; recall:  70.82%; FB1:  79.57\n",
      "             MISC: precision:  75.84%; recall:  75.60%; FB1:  75.72\n",
      "              ORG: precision:  70.07%; recall:  66.52%; FB1:  68.25\n",
      "              PER: precision:  79.91%; recall:  88.11%; FB1:  83.81\n",
      "\n",
      "epoch = 12\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5984 phrases; correct: 4780.\n",
      "accuracy:  96.99%; precision:  79.88%; recall:  80.44%; FB1:  80.16\n",
      "              LOC: precision:  81.14%; recall:  85.74%; FB1:  83.38\n",
      "             MISC: precision:  75.05%; recall:  77.98%; FB1:  76.49\n",
      "              ORG: precision:  73.82%; recall:  70.84%; FB1:  72.30\n",
      "              PER: precision:  85.43%; recall:  83.39%; FB1:  84.40\n",
      "\n",
      "epoch = 13\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5615 phrases; correct: 4627.\n",
      "accuracy:  96.75%; precision:  82.40%; recall:  77.87%; FB1:  80.07\n",
      "              LOC: precision:  86.05%; recall:  82.96%; FB1:  84.48\n",
      "             MISC: precision:  79.55%; recall:  76.79%; FB1:  78.15\n",
      "              ORG: precision:  75.41%; recall:  61.30%; FB1:  67.63\n",
      "              PER: precision:  84.39%; recall:  85.40%; FB1:  84.89\n",
      "\n",
      "epoch = 14\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5829 phrases; correct: 4641.\n",
      "accuracy:  96.67%; precision:  79.62%; recall:  78.11%; FB1:  78.85\n",
      "              LOC: precision:  89.14%; recall:  74.14%; FB1:  80.95\n",
      "             MISC: precision:  70.07%; recall:  81.24%; FB1:  75.24\n",
      "              ORG: precision:  75.40%; recall:  66.52%; FB1:  70.68\n",
      "              PER: precision:  79.94%; recall:  88.93%; FB1:  84.19\n",
      "\n",
      "epoch = 15\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5575 phrases; correct: 4576.\n",
      "accuracy:  96.63%; precision:  82.08%; recall:  77.01%; FB1:  79.47\n",
      "              LOC: precision:  85.01%; recall:  80.89%; FB1:  82.90\n",
      "             MISC: precision:  80.05%; recall:  75.70%; FB1:  77.81\n",
      "              ORG: precision:  73.47%; recall:  65.47%; FB1:  69.24\n",
      "              PER: precision:  86.02%; recall:  82.19%; FB1:  84.06\n",
      "\n",
      "epoch = 16\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5773 phrases; correct: 4552.\n",
      "accuracy:  96.53%; precision:  78.85%; recall:  76.61%; FB1:  77.71\n",
      "              LOC: precision:  86.68%; recall:  79.37%; FB1:  82.86\n",
      "             MISC: precision:  66.01%; recall:  80.26%; FB1:  72.44\n",
      "              ORG: precision:  71.18%; recall:  72.93%; FB1:  72.04\n",
      "              PER: precision:  86.22%; recall:  74.70%; FB1:  80.05\n",
      "\n",
      "epoch = 17\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5076 phrases; correct: 4192.\n",
      "accuracy:  95.78%; precision:  82.58%; recall:  70.55%; FB1:  76.09\n",
      "              LOC: precision:  89.04%; recall:  76.92%; FB1:  82.54\n",
      "             MISC: precision:  81.86%; recall:  73.43%; FB1:  77.42\n",
      "              ORG: precision:  71.16%; recall:  57.42%; FB1:  63.56\n",
      "              PER: precision:  84.30%; recall:  72.31%; FB1:  77.85\n",
      "\n",
      "epoch = 18\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5445 phrases; correct: 4535.\n",
      "accuracy:  96.54%; precision:  83.29%; recall:  76.32%; FB1:  79.65\n",
      "              LOC: precision:  86.54%; recall:  78.72%; FB1:  82.44\n",
      "             MISC: precision:  82.49%; recall:  74.62%; FB1:  78.36\n",
      "              ORG: precision:  74.42%; recall:  69.65%; FB1:  71.96\n",
      "              PER: precision:  87.06%; recall:  79.64%; FB1:  83.19\n",
      "\n",
      "epoch = 19\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5607 phrases; correct: 4560.\n",
      "accuracy:  96.58%; precision:  81.33%; recall:  76.74%; FB1:  78.97\n",
      "              LOC: precision:  89.78%; recall:  75.07%; FB1:  81.77\n",
      "             MISC: precision:  73.72%; recall:  79.39%; FB1:  76.45\n",
      "              ORG: precision:  70.77%; recall:  74.20%; FB1:  72.44\n",
      "              PER: precision:  86.96%; recall:  78.94%; FB1:  82.75\n",
      "\n",
      "epoch = 20\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5955 phrases; correct: 4547.\n",
      "accuracy:  96.38%; precision:  76.36%; recall:  76.52%; FB1:  76.44\n",
      "              LOC: precision:  73.33%; recall:  90.42%; FB1:  80.98\n",
      "             MISC: precision:  68.61%; recall:  79.18%; FB1:  73.51\n",
      "              ORG: precision:  77.66%; recall:  57.05%; FB1:  65.78\n",
      "              PER: precision:  84.77%; recall:  75.52%; FB1:  79.87\n",
      "\n",
      "epoch = 21\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5348 phrases; correct: 4371.\n",
      "accuracy:  96.17%; precision:  81.73%; recall:  73.56%; FB1:  77.43\n",
      "              LOC: precision:  90.56%; recall:  72.07%; FB1:  80.27\n",
      "             MISC: precision:  71.12%; recall:  78.52%; FB1:  74.64\n",
      "              ORG: precision:  74.53%; recall:  70.69%; FB1:  72.56\n",
      "              PER: precision:  86.15%; recall:  74.65%; FB1:  79.99\n",
      "\n",
      "epoch = 22\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5894 phrases; correct: 4771.\n",
      "accuracy:  96.98%; precision:  80.95%; recall:  80.29%; FB1:  80.62\n",
      "              LOC: precision:  90.19%; recall:  78.55%; FB1:  83.97\n",
      "             MISC: precision:  78.85%; recall:  77.66%; FB1:  78.25\n",
      "              ORG: precision:  66.84%; recall:  78.30%; FB1:  72.12\n",
      "              PER: precision:  86.06%; recall:  84.80%; FB1:  85.43\n",
      "\n",
      "epoch = 23\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5400 phrases; correct: 4432.\n",
      "accuracy:  96.37%; precision:  82.07%; recall:  74.59%; FB1:  78.15\n",
      "              LOC: precision:  87.54%; recall:  79.97%; FB1:  83.58\n",
      "             MISC: precision:  79.73%; recall:  76.36%; FB1:  78.01\n",
      "              ORG: precision:  72.83%; recall:  65.18%; FB1:  68.79\n",
      "              PER: precision:  84.50%; recall:  75.19%; FB1:  79.57\n",
      "\n",
      "epoch = 24\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5341 phrases; correct: 4456.\n",
      "accuracy:  96.41%; precision:  83.43%; recall:  74.99%; FB1:  78.99\n",
      "              LOC: precision:  88.25%; recall:  78.88%; FB1:  83.30\n",
      "             MISC: precision:  78.76%; recall:  76.03%; FB1:  77.37\n",
      "              ORG: precision:  74.56%; recall:  66.22%; FB1:  70.14\n",
      "              PER: precision:  87.64%; recall:  76.98%; FB1:  81.97\n",
      "\n",
      "epoch = 25\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5574 phrases; correct: 4603.\n",
      "accuracy:  96.64%; precision:  82.58%; recall:  77.47%; FB1:  79.94\n",
      "              LOC: precision:  85.74%; recall:  82.47%; FB1:  84.07\n",
      "             MISC: precision:  79.18%; recall:  77.11%; FB1:  78.13\n",
      "              ORG: precision:  75.34%; recall:  73.83%; FB1:  74.58\n",
      "              PER: precision:  86.96%; recall:  75.30%; FB1:  80.71\n",
      "\n",
      "epoch = 26\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5731 phrases; correct: 4735.\n",
      "accuracy:  96.97%; precision:  82.62%; recall:  79.69%; FB1:  81.13\n",
      "              LOC: precision:  87.13%; recall:  84.00%; FB1:  85.53\n",
      "             MISC: precision:  76.01%; recall:  77.33%; FB1:  76.67\n",
      "              ORG: precision:  75.22%; recall:  70.84%; FB1:  72.96\n",
      "              PER: precision:  86.92%; recall:  83.01%; FB1:  84.92\n",
      "\n",
      "epoch = 27\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5932 phrases; correct: 4633.\n",
      "accuracy:  96.68%; precision:  78.10%; recall:  77.97%; FB1:  78.04\n",
      "              LOC: precision:  89.76%; recall:  73.98%; FB1:  81.11\n",
      "             MISC: precision:  70.92%; recall:  79.61%; FB1:  75.01\n",
      "              ORG: precision:  62.98%; recall:  79.94%; FB1:  70.46\n",
      "              PER: precision:  87.33%; recall:  79.70%; FB1:  83.34\n",
      "\n",
      "epoch = 28\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5522 phrases; correct: 4591.\n",
      "accuracy:  96.63%; precision:  83.14%; recall:  77.26%; FB1:  80.09\n",
      "              LOC: precision:  85.83%; recall:  78.50%; FB1:  82.00\n",
      "             MISC: precision:  83.83%; recall:  73.64%; FB1:  78.41\n",
      "              ORG: precision:  75.92%; recall:  69.35%; FB1:  72.49\n",
      "              PER: precision:  85.22%; recall:  83.60%; FB1:  84.41\n",
      "\n",
      "epoch = 29\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5510 phrases; correct: 4371.\n",
      "accuracy:  96.14%; precision:  79.33%; recall:  73.56%; FB1:  76.34\n",
      "              LOC: precision:  86.08%; recall:  77.79%; FB1:  81.73\n",
      "             MISC: precision:  78.44%; recall:  75.38%; FB1:  76.88\n",
      "              ORG: precision:  66.49%; recall:  74.12%; FB1:  70.10\n",
      "              PER: precision:  85.30%; recall:  68.02%; FB1:  75.69\n",
      "\n",
      "epoch = 30\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5861 phrases; correct: 4735.\n",
      "accuracy:  96.91%; precision:  80.79%; recall:  79.69%; FB1:  80.23\n",
      "              LOC: precision:  82.49%; recall:  88.24%; FB1:  85.27\n",
      "             MISC: precision:  77.78%; recall:  75.16%; FB1:  76.45\n",
      "              ORG: precision:  71.28%; recall:  76.06%; FB1:  73.59\n",
      "              PER: precision:  89.01%; recall:  76.06%; FB1:  82.03\n",
      "\n",
      "epoch = 31\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5393 phrases; correct: 4318.\n",
      "accuracy:  96.00%; precision:  80.07%; recall:  72.67%; FB1:  76.19\n",
      "              LOC: precision:  86.70%; recall:  76.97%; FB1:  81.55\n",
      "             MISC: precision:  71.40%; recall:  78.52%; FB1:  74.79\n",
      "              ORG: precision:  71.81%; recall:  67.64%; FB1:  69.66\n",
      "              PER: precision:  85.72%; recall:  69.11%; FB1:  76.53\n",
      "\n",
      "epoch = 32\n",
      "\n",
      "processed 51362 tokens with 5942 phrases; found: 5154 phrases; correct: 4342.\n",
      "accuracy:  96.16%; precision:  84.25%; recall:  73.07%; FB1:  78.26\n",
      "              LOC: precision:  90.50%; recall:  76.21%; FB1:  82.74\n",
      "             MISC: precision:  77.62%; recall:  76.36%; FB1:  76.98\n",
      "              ORG: precision:  77.19%; recall:  65.85%; FB1:  71.07\n",
      "              PER: precision:  87.08%; recall:  73.56%; FB1:  79.75\n",
      "\n",
      "epoch = 33\n"
     ]
    }
   ],
   "source": [
    "W = {}\n",
    "epoch = 100\n",
    "for e in range(epoch):\n",
    "    print('epoch = '+ str(e+1))\n",
    "    # training\n",
    "    for sentence in text_train:\n",
    "\n",
    "        words = [' '.join([s[0],s[1]]) for s in sentence]\n",
    "        word_tags = [s[-1] for s in sentence]\n",
    "\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "        w_true = create_features(words, word_tags)\n",
    "        w_pred = create_features(words, y_pred)\n",
    "        for wt in w_true:\n",
    "            if wt in W: W[wt] += w_true[wt]\n",
    "            else: W[wt] = w_true[wt]\n",
    "\n",
    "        for wp in w_pred:\n",
    "            if wp in W: W[wp] -= w_pred[wp]\n",
    "            else: W[wp] = -w_pred[wp]\n",
    "                \n",
    "    # predicting            \n",
    "    filename = 'result_SPViterbi.txt'\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    save_wt = '\\n'\n",
    "    for sentence in text_pred:\n",
    "        words = [' '.join([s[0],s[1]]) for s in sentence]\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "\n",
    "        for wt in range(len(sentence)):\n",
    "            save_wt += sentence[wt][0]+' '+sentence[wt][1]+' '+sentence[wt][2]+' '+sentence[wt][3]+' '+y_pred[wt]+'\\n'\n",
    "\n",
    "        save_wt += '\\n'\n",
    "\n",
    "    with open('result_SPViterbi.txt', 'w+') as txt_file:\n",
    "        txt_file.write(save_wt)\n",
    "\n",
    "    output = subprocess.run(\"/usr/bin/perl -w conlleval < result_SPViterbi.txt\", shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "    print('\\n'+output.stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

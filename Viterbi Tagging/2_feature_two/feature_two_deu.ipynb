{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [t.strip().split(' ')[-1] for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- -X- O\\n',open(\"../data/conll03/deu.train\", encoding=\"ISO-8859-1\").readlines())) if len(t.strip().split(' '))>1]\n",
    "tags = sorted(list(set(tags)))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def if_has_W(feature):\n",
    "    if feature not in W:\n",
    "        return 0\n",
    "    else:\n",
    "        return W[feature]\n",
    "\n",
    "\n",
    "def Pre_Next(): # ('NN','NN')\n",
    "    P_tags  =[] \n",
    "    for pt in tags:\n",
    "        tp_P_tags = []\n",
    "        for nt in tags:\n",
    "            tp_P_tags.append(if_has_W(('pt '+nt,'t '+pt)))\n",
    "        P_tags.append(tp_P_tags)\n",
    "    P_tags = np.asarray(P_tags)\n",
    "    return P_tags\n",
    "\n",
    "\n",
    "def hmm_viterbi(W, words):\n",
    "    y_pred = []\n",
    "    i= 0\n",
    "    aug_words = ['__SENTINEL__ O', '__SENTINEL__ O'] + words + ['__SENTINEL__ O', '__SENTINEL__ O']\n",
    "    for ppw_, pw_, w_, nw_, nnw_ in zip(aug_words, aug_words[1:], aug_words[2:], aug_words[3:], aug_words[4:]):\n",
    "        # NOTE: No pt, ppt attribs currently\n",
    "        ppw = ppw_.split(' ')[0]\n",
    "        pw = pw_.split(' ')[0]\n",
    "        w = w_.split(' ')[0]\n",
    "        nw = nw_.split(' ')[0]\n",
    "        nnw = nnw_.split(' ')[0]\n",
    "\n",
    "        ppt = ppw_.split(' ')[1]\n",
    "        pt = pw_.split(' ')[1]\n",
    "        t = w_.split(' ')[1]\n",
    "        nt = nw_.split(' ')[1]\n",
    "        nnt = nnw_.split(' ')[1]\n",
    "\n",
    "\n",
    "        attribs = {'ppw ' + ppw,\n",
    "                   'pw ' + pw,\n",
    "                   'w ' + w,\n",
    "                   'nw ' + nw,\n",
    "                   'nnw ' + nnw,\n",
    "                   'ppt '+ppt,\n",
    "                   'pt '+pt,\n",
    "                   't '+t,\n",
    "                   'nt '+nt,\n",
    "                   'nnt '+nnt\n",
    "                   }\n",
    "\n",
    "        if re.search('[0-9]', w):\n",
    "            attribs.add('dig __NONE__')\n",
    "        if re.search('[A-Z]', w):\n",
    "            attribs.add('uc __NONE__')\n",
    "        if '-' in w:\n",
    "            attribs.add('hyph __NONE__')\n",
    "        \n",
    "        score_list = []\n",
    "        for tag in tags:\n",
    "            score = 0\n",
    "            for a in attribs:\n",
    "                if (a, tag) in W:\n",
    "                    score += W[(a, tag)]\n",
    "            score_list.append(score)\n",
    "        \n",
    "        #Viterbi\n",
    "        if i == 0:\n",
    "            data = words[i]\n",
    "            first_level = []\n",
    "            for tag_number in range(len(tags)):   \n",
    "                first_level.append((if_has_W(('pt '+'','t '+tag))+score_list[tag_number]))\n",
    "            y_pred.append(tags[first_level.index(max(first_level))])\n",
    "            next_value = first_level\n",
    "        else:\n",
    "            data = words[i]\n",
    "            probility = ((next_value + Pre_Next()).T + [score_list[tag_number] for tag_number in range(len(tags))]).T\n",
    "            y_pred.append(tags[probility.max(axis=1).argmax()])\n",
    "            next_value = probility.max(axis=1)\n",
    "\n",
    "        i+=1\n",
    "    return y_pred\n",
    "\n",
    "def create_features(words, word_tags):\n",
    "    loc = 0\n",
    "    w_temp = {}\n",
    "    aug_words = ['__SENTINEL__ O', '__SENTINEL__ O'] + words + ['__SENTINEL__ O', '__SENTINEL__ O']\n",
    "\n",
    "    for ppw_, pw_, w_, nw_, nnw_ in zip(aug_words, aug_words[1:], aug_words[2:], aug_words[3:], aug_words[4:]):\n",
    "        # NOTE: No pt, ppt attribs currently\n",
    "        ppw = ppw_.split(' ')[0]\n",
    "        pw = pw_.split(' ')[0]\n",
    "        w = w_.split(' ')[0]\n",
    "        nw = nw_.split(' ')[0]\n",
    "        nnw = nnw_.split(' ')[0]\n",
    "\n",
    "        ppt = ppw_.split(' ')[1]\n",
    "        pt = pw_.split(' ')[1]\n",
    "        t = w_.split(' ')[1]\n",
    "        nt = nw_.split(' ')[1]\n",
    "        nnt = nnw_.split(' ')[1]\n",
    "\n",
    "\n",
    "        attribs = {'ppw ' + ppw,\n",
    "                   'pw ' + pw,\n",
    "                   'w ' + w,\n",
    "                   'nw ' + nw,\n",
    "                   'nnw ' + nnw\n",
    "                   }\n",
    "\n",
    "        if re.search('[0-9]', w):\n",
    "            attribs.add('dig __NONE__')\n",
    "        if re.search('[A-Z]', w):\n",
    "            attribs.add('uc __NONE__')\n",
    "        if '-' in w:\n",
    "            attribs.add('hyph __NONE__')\n",
    "\n",
    "        for a in attribs:\n",
    "            if (a, word_tags[loc]) in w_temp:\n",
    "                w_temp[(a, word_tags[loc])] += 1\n",
    "            else: w_temp[(a, word_tags[loc])] = 1\n",
    "\n",
    "        attribs = {\n",
    "                   'ppt '+ppt,\n",
    "                   'pt '+pt,\n",
    "                   't '+t,\n",
    "                   'nt '+nt,\n",
    "                   'nnt '+nnt\n",
    "                    }\n",
    "\n",
    "        for a in attribs:\n",
    "            if (a, word_tags[loc]) in w_temp:\n",
    "                w_temp[(a, word_tags[loc])] += 0.01\n",
    "            else: w_temp[(a, word_tags[loc])] = 0.01\n",
    "        loc += 1\n",
    "        \n",
    "        \n",
    "    for i in range(len(word_tags)+1):\n",
    "        if i == 0:\n",
    "            first_tag = 'pt '+''\n",
    "        else:\n",
    "            first_tag = 'pt '+word_tags[i-1]\n",
    "        \n",
    "        if i == len(word_tags):\n",
    "            next_tag = 't '+''\n",
    "        else:\n",
    "            next_tag = 't '+word_tags[i]\n",
    "            \n",
    "            if (first_tag,next_tag) not in w_temp:\n",
    "                w_temp[(first_tag,next_tag)] = 0.001#create_trans((tags[i-1],tags[i]))\n",
    "            else:\n",
    "                w_temp[(first_tag,next_tag)] += 0.001#create_trans((tags[i-1],tags[i]))\n",
    "\n",
    "    return w_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Ereignis', 'Ereignis', 'NN', 'I-NC', 'O'],\n",
       "  ['und', 'und', 'KON', 'O', 'O'],\n",
       "  ['Erzählung', 'Erzählung', 'NN', 'I-NC', 'O'],\n",
       "  ['oder', 'oder', 'KON', 'I-NC', 'O'],\n",
       "  [':', ':', '$.', 'O', 'O']]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- -X- O\\n',open(\"../data/conll03/deu.train\", encoding=\"ISO-8859-1\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_train = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Großer', 'Große', 'NN', 'I-NC', 'O'],\n",
       "  ['Foto-Wettbeweb', '<unknown>', 'NN', 'I-NC', 'O'],\n",
       "  ['\"', '\"', '$(', 'O', 'O'],\n",
       "  ['Nordendler', '<unknown>', 'NN', 'I-NC', 'I-ORG'],\n",
       "  ['\"', '\"', '$(', 'O', 'O'],\n",
       "  ['laden', 'laden', 'VVFIN', 'I-VC', 'O'],\n",
       "  ['die', 'd', 'ART', 'I-NC', 'O'],\n",
       "  ['Nordendler', '<unknown>', 'NN', 'I-NC', 'I-MISC'],\n",
       "  ['ein', 'ein', 'ART', 'B-NC', 'O']]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [t.strip().split(' ') for t in list(filter(lambda x:x != '-DOCSTART- -X- -X- -X- O\\n',open(\"../data/conll03/deu.testa\", encoding=\"ISO-8859-1\").readlines()))]\n",
    "sen_locs = [t for t in range(len(text)) if len(text[t])==1]\n",
    "text_pred = [[text[s] for s in range(sen_locs[loc]+1,sen_locs[loc+1])] for loc in range(len(sen_locs)-1)]\n",
    "text_pred[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2814 phrases; correct: 1191.\n",
      "accuracy:  90.07%; precision:  42.32%; recall:  24.64%; FB1:  31.15\n",
      "              LOC: precision:  40.86%; recall:  24.22%; FB1:  30.41\n",
      "             MISC: precision:  50.50%; recall:  15.05%; FB1:  23.19\n",
      "              ORG: precision:  41.76%; recall:  20.23%; FB1:  27.25\n",
      "              PER: precision:  41.42%; recall:  35.83%; FB1:  38.42\n",
      "\n",
      "epoch = 2\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3199 phrases; correct: 1486.\n",
      "accuracy:  90.65%; precision:  46.45%; recall:  30.75%; FB1:  37.00\n",
      "              LOC: precision:  53.05%; recall:  41.24%; FB1:  46.40\n",
      "             MISC: precision:  53.33%; recall:  13.47%; FB1:  21.50\n",
      "              ORG: precision:  37.98%; recall:  23.29%; FB1:  28.87\n",
      "              PER: precision:  45.38%; recall:  40.97%; FB1:  43.06\n",
      "\n",
      "epoch = 3\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3667 phrases; correct: 1600.\n",
      "accuracy:  91.07%; precision:  43.63%; recall:  33.11%; FB1:  37.65\n",
      "              LOC: precision:  33.30%; recall:  57.07%; FB1:  42.06\n",
      "             MISC: precision:  57.06%; recall:  20.00%; FB1:  29.62\n",
      "              ORG: precision:  51.09%; recall:  26.51%; FB1:  34.91\n",
      "              PER: precision:  61.24%; recall:  28.19%; FB1:  38.61\n",
      "\n",
      "epoch = 4\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3161 phrases; correct: 1689.\n",
      "accuracy:  91.78%; precision:  53.43%; recall:  34.95%; FB1:  42.26\n",
      "              LOC: precision:  59.48%; recall:  40.39%; FB1:  48.11\n",
      "             MISC: precision:  68.64%; recall:  16.04%; FB1:  26.00\n",
      "              ORG: precision:  55.45%; recall:  28.69%; FB1:  37.81\n",
      "              PER: precision:  46.86%; recall:  49.54%; FB1:  48.16\n",
      "\n",
      "epoch = 5\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4154 phrases; correct: 1909.\n",
      "accuracy:  91.85%; precision:  45.96%; recall:  39.50%; FB1:  42.48\n",
      "              LOC: precision:  37.30%; recall:  51.99%; FB1:  43.44\n",
      "             MISC: precision:  51.89%; recall:  28.61%; FB1:  36.89\n",
      "              ORG: precision:  43.53%; recall:  34.41%; FB1:  38.43\n",
      "              PER: precision:  59.69%; recall:  41.33%; FB1:  48.84\n",
      "\n",
      "epoch = 6\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2831 phrases; correct: 1696.\n",
      "accuracy:  92.11%; precision:  59.91%; recall:  35.09%; FB1:  44.26\n",
      "              LOC: precision:  52.02%; recall:  49.03%; FB1:  50.48\n",
      "             MISC: precision:  70.72%; recall:  21.29%; FB1:  32.72\n",
      "              ORG: precision:  60.37%; recall:  34.00%; FB1:  43.51\n",
      "              PER: precision:  67.13%; recall:  34.26%; FB1:  45.37\n",
      "\n",
      "epoch = 7\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3812 phrases; correct: 2052.\n",
      "accuracy:  92.52%; precision:  53.83%; recall:  42.46%; FB1:  47.47\n",
      "              LOC: precision:  54.51%; recall:  52.75%; FB1:  53.61\n",
      "             MISC: precision:  57.28%; recall:  30.40%; FB1:  39.72\n",
      "              ORG: precision:  46.09%; recall:  48.51%; FB1:  47.27\n",
      "              PER: precision:  62.88%; recall:  37.12%; FB1:  46.68\n",
      "\n",
      "epoch = 8\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3507 phrases; correct: 1845.\n",
      "accuracy:  92.18%; precision:  52.61%; recall:  38.18%; FB1:  44.24\n",
      "              LOC: precision:  45.07%; recall:  53.01%; FB1:  48.72\n",
      "             MISC: precision:  58.33%; recall:  25.64%; FB1:  35.63\n",
      "              ORG: precision:  52.68%; recall:  38.76%; FB1:  44.66\n",
      "              PER: precision:  62.94%; recall:  34.19%; FB1:  44.31\n",
      "\n",
      "epoch = 9\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3493 phrases; correct: 1853.\n",
      "accuracy:  92.21%; precision:  53.05%; recall:  38.34%; FB1:  44.51\n",
      "              LOC: precision:  47.59%; recall:  53.60%; FB1:  50.42\n",
      "             MISC: precision:  61.25%; recall:  21.29%; FB1:  31.59\n",
      "              ORG: precision:  45.86%; recall:  40.13%; FB1:  42.80\n",
      "              PER: precision:  69.83%; recall:  36.19%; FB1:  47.67\n",
      "\n",
      "epoch = 10\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3881 phrases; correct: 2085.\n",
      "accuracy:  92.63%; precision:  53.72%; recall:  43.14%; FB1:  47.85\n",
      "              LOC: precision:  50.11%; recall:  58.00%; FB1:  53.77\n",
      "             MISC: precision:  59.07%; recall:  30.30%; FB1:  40.05\n",
      "              ORG: precision:  47.86%; recall:  36.91%; FB1:  41.67\n",
      "              PER: precision:  61.21%; recall:  45.40%; FB1:  52.13\n",
      "\n",
      "epoch = 11\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 4083 phrases; correct: 2170.\n",
      "accuracy:  92.59%; precision:  53.15%; recall:  44.90%; FB1:  48.68\n",
      "              LOC: precision:  52.07%; recall:  56.48%; FB1:  54.18\n",
      "             MISC: precision:  70.66%; recall:  16.93%; FB1:  27.32\n",
      "              ORG: precision:  48.89%; recall:  39.16%; FB1:  43.49\n",
      "              PER: precision:  54.02%; recall:  60.39%; FB1:  57.03\n",
      "\n",
      "epoch = 12\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2872 phrases; correct: 1820.\n",
      "accuracy:  92.55%; precision:  63.37%; recall:  37.66%; FB1:  47.24\n",
      "              LOC: precision:  64.22%; recall:  41.49%; FB1:  50.41\n",
      "             MISC: precision:  72.87%; recall:  22.87%; FB1:  34.82\n",
      "              ORG: precision:  56.75%; recall:  43.03%; FB1:  48.95\n",
      "              PER: precision:  66.39%; recall:  40.33%; FB1:  50.18\n",
      "\n",
      "epoch = 13\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3799 phrases; correct: 2040.\n",
      "accuracy:  92.70%; precision:  53.70%; recall:  42.21%; FB1:  47.27\n",
      "              LOC: precision:  50.12%; recall:  54.70%; FB1:  52.31\n",
      "             MISC: precision:  60.99%; recall:  29.41%; FB1:  39.68\n",
      "              ORG: precision:  51.63%; recall:  34.41%; FB1:  41.30\n",
      "              PER: precision:  56.02%; recall:  47.82%; FB1:  51.60\n",
      "\n",
      "epoch = 14\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3134 phrases; correct: 1855.\n",
      "accuracy:  92.42%; precision:  59.19%; recall:  38.38%; FB1:  46.57\n",
      "              LOC: precision:  62.82%; recall:  45.22%; FB1:  52.58\n",
      "             MISC: precision:  69.83%; recall:  20.40%; FB1:  31.57\n",
      "              ORG: precision:  56.32%; recall:  32.31%; FB1:  41.07\n",
      "              PER: precision:  55.91%; recall:  50.96%; FB1:  53.32\n",
      "\n",
      "epoch = 15\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2931 phrases; correct: 1738.\n",
      "accuracy:  92.36%; precision:  59.30%; recall:  35.96%; FB1:  44.77\n",
      "              LOC: precision:  52.95%; recall:  50.97%; FB1:  51.94\n",
      "             MISC: precision:  76.60%; recall:  20.10%; FB1:  31.84\n",
      "              ORG: precision:  58.71%; recall:  30.14%; FB1:  39.83\n",
      "              PER: precision:  62.67%; recall:  39.90%; FB1:  48.76\n",
      "\n",
      "epoch = 16\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2553 phrases; correct: 1524.\n",
      "accuracy:  91.82%; precision:  59.69%; recall:  31.53%; FB1:  41.27\n",
      "              LOC: precision:  50.36%; recall:  46.91%; FB1:  48.58\n",
      "             MISC: precision:  73.58%; recall:  19.31%; FB1:  30.59\n",
      "              ORG: precision:  63.14%; recall:  31.75%; FB1:  42.25\n",
      "              PER: precision:  67.55%; recall:  27.19%; FB1:  38.78\n",
      "\n",
      "epoch = 17\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3006 phrases; correct: 1744.\n",
      "accuracy:  92.30%; precision:  58.02%; recall:  36.09%; FB1:  44.50\n",
      "              LOC: precision:  51.78%; recall:  50.55%; FB1:  51.16\n",
      "             MISC: precision:  71.75%; recall:  22.38%; FB1:  34.11\n",
      "              ORG: precision:  55.82%; recall:  40.93%; FB1:  47.23\n",
      "              PER: precision:  65.76%; recall:  29.48%; FB1:  40.71\n",
      "\n",
      "epoch = 18\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3353 phrases; correct: 2005.\n",
      "accuracy:  92.86%; precision:  59.80%; recall:  41.49%; FB1:  48.99\n",
      "              LOC: precision:  66.14%; recall:  49.45%; FB1:  56.59\n",
      "             MISC: precision:  77.17%; recall:  19.41%; FB1:  31.01\n",
      "              ORG: precision:  51.75%; recall:  38.03%; FB1:  43.85\n",
      "              PER: precision:  57.75%; recall:  53.75%; FB1:  55.67\n",
      "\n",
      "epoch = 19\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2789 phrases; correct: 1715.\n",
      "accuracy:  92.18%; precision:  61.49%; recall:  35.49%; FB1:  45.00\n",
      "              LOC: precision:  56.00%; recall:  48.18%; FB1:  51.80\n",
      "             MISC: precision:  76.49%; recall:  20.30%; FB1:  32.08\n",
      "              ORG: precision:  61.90%; recall:  32.47%; FB1:  42.60\n",
      "              PER: precision:  63.00%; recall:  38.40%; FB1:  47.72\n",
      "\n",
      "epoch = 20\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3366 phrases; correct: 1867.\n",
      "accuracy:  92.47%; precision:  55.47%; recall:  38.63%; FB1:  45.54\n",
      "              LOC: precision:  48.99%; recall:  53.60%; FB1:  51.19\n",
      "             MISC: precision:  74.10%; recall:  22.38%; FB1:  34.37\n",
      "              ORG: precision:  51.38%; recall:  37.55%; FB1:  43.39\n",
      "              PER: precision:  62.88%; recall:  38.69%; FB1:  47.90\n",
      "\n",
      "epoch = 21\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3248 phrases; correct: 1875.\n",
      "accuracy:  92.60%; precision:  57.73%; recall:  38.80%; FB1:  46.41\n",
      "              LOC: precision:  54.00%; recall:  53.18%; FB1:  53.58\n",
      "             MISC: precision:  77.73%; recall:  19.70%; FB1:  31.44\n",
      "              ORG: precision:  56.65%; recall:  37.07%; FB1:  44.81\n",
      "              PER: precision:  57.82%; recall:  41.97%; FB1:  48.64\n",
      "\n",
      "epoch = 22\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3330 phrases; correct: 1874.\n",
      "accuracy:  92.57%; precision:  56.28%; recall:  38.78%; FB1:  45.91\n",
      "              LOC: precision:  53.39%; recall:  51.99%; FB1:  52.68\n",
      "             MISC: precision:  73.29%; recall:  22.28%; FB1:  34.17\n",
      "              ORG: precision:  50.31%; recall:  39.73%; FB1:  44.39\n",
      "              PER: precision:  60.69%; recall:  38.69%; FB1:  47.25\n",
      "\n",
      "epoch = 23\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3295 phrases; correct: 1968.\n",
      "accuracy:  92.76%; precision:  59.73%; recall:  40.72%; FB1:  48.43\n",
      "              LOC: precision:  63.06%; recall:  47.42%; FB1:  54.13\n",
      "             MISC: precision:  74.73%; recall:  20.20%; FB1:  31.80\n",
      "              ORG: precision:  55.73%; recall:  39.56%; FB1:  46.28\n",
      "              PER: precision:  56.90%; recall:  50.89%; FB1:  53.73\n",
      "\n",
      "epoch = 24\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3390 phrases; correct: 1846.\n",
      "accuracy:  92.37%; precision:  54.45%; recall:  38.20%; FB1:  44.90\n",
      "              LOC: precision:  48.46%; recall:  55.88%; FB1:  51.91\n",
      "             MISC: precision:  74.01%; recall:  22.28%; FB1:  34.25\n",
      "              ORG: precision:  48.72%; recall:  39.73%; FB1:  43.76\n",
      "              PER: precision:  65.73%; recall:  33.40%; FB1:  44.30\n",
      "\n",
      "epoch = 25\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3260 phrases; correct: 1884.\n",
      "accuracy:  92.54%; precision:  57.79%; recall:  38.98%; FB1:  46.56\n",
      "              LOC: precision:  54.34%; recall:  50.38%; FB1:  52.28\n",
      "             MISC: precision:  72.64%; recall:  21.29%; FB1:  32.92\n",
      "              ORG: precision:  53.09%; recall:  38.03%; FB1:  44.32\n",
      "              PER: precision:  61.43%; recall:  42.97%; FB1:  50.57\n",
      "\n",
      "epoch = 26\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2748 phrases; correct: 1769.\n",
      "accuracy:  92.45%; precision:  64.37%; recall:  36.60%; FB1:  46.67\n",
      "              LOC: precision:  69.14%; recall:  47.25%; FB1:  56.14\n",
      "             MISC: precision:  75.79%; recall:  18.91%; FB1:  30.27\n",
      "              ORG: precision:  56.85%; recall:  38.11%; FB1:  45.63\n",
      "              PER: precision:  63.83%; recall:  39.04%; FB1:  48.45\n",
      "\n",
      "epoch = 27\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2928 phrases; correct: 1721.\n",
      "accuracy:  92.11%; precision:  58.78%; recall:  35.61%; FB1:  44.35\n",
      "              LOC: precision:  56.54%; recall:  47.59%; FB1:  51.68\n",
      "             MISC: precision:  64.01%; recall:  27.82%; FB1:  38.79\n",
      "              ORG: precision:  56.17%; recall:  34.49%; FB1:  42.74\n",
      "              PER: precision:  61.39%; recall:  32.12%; FB1:  42.17\n",
      "\n",
      "epoch = 28\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2679 phrases; correct: 1639.\n",
      "accuracy:  92.22%; precision:  61.18%; recall:  33.91%; FB1:  43.64\n",
      "              LOC: precision:  74.03%; recall:  37.17%; FB1:  49.49\n",
      "             MISC: precision:  69.91%; recall:  22.08%; FB1:  33.56\n",
      "              ORG: precision:  50.49%; recall:  45.45%; FB1:  47.84\n",
      "              PER: precision:  63.54%; recall:  29.48%; FB1:  40.27\n",
      "\n",
      "epoch = 29\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3108 phrases; correct: 1902.\n",
      "accuracy:  92.63%; precision:  61.20%; recall:  39.35%; FB1:  47.90\n",
      "              LOC: precision:  61.47%; recall:  46.74%; FB1:  53.10\n",
      "             MISC: precision:  73.44%; recall:  23.27%; FB1:  35.34\n",
      "              ORG: precision:  54.49%; recall:  38.11%; FB1:  44.86\n",
      "              PER: precision:  62.82%; recall:  45.82%; FB1:  52.99\n",
      "\n",
      "epoch = 30\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2747 phrases; correct: 1776.\n",
      "accuracy:  92.40%; precision:  64.65%; recall:  36.75%; FB1:  46.86\n",
      "              LOC: precision:  69.25%; recall:  41.57%; FB1:  51.96\n",
      "             MISC: precision:  69.82%; recall:  23.37%; FB1:  35.01\n",
      "              ORG: precision:  63.47%; recall:  33.04%; FB1:  43.46\n",
      "              PER: precision:  60.63%; recall:  45.61%; FB1:  52.06\n",
      "\n",
      "epoch = 31\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2834 phrases; correct: 1657.\n",
      "accuracy:  92.04%; precision:  58.47%; recall:  34.29%; FB1:  43.22\n",
      "              LOC: precision:  50.00%; recall:  49.53%; FB1:  49.77\n",
      "             MISC: precision:  72.73%; recall:  22.97%; FB1:  34.91\n",
      "              ORG: precision:  59.42%; recall:  31.51%; FB1:  41.18\n",
      "              PER: precision:  65.36%; recall:  32.05%; FB1:  43.01\n",
      "\n",
      "epoch = 32\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2775 phrases; correct: 1605.\n",
      "accuracy:  91.97%; precision:  57.84%; recall:  33.21%; FB1:  42.19\n",
      "              LOC: precision:  51.54%; recall:  49.53%; FB1:  50.52\n",
      "             MISC: precision:  78.97%; recall:  19.70%; FB1:  31.54\n",
      "              ORG: precision:  58.67%; recall:  28.36%; FB1:  38.24\n",
      "              PER: precision:  59.52%; recall:  33.48%; FB1:  42.85\n",
      "\n",
      "epoch = 33\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2997 phrases; correct: 1755.\n",
      "accuracy:  92.38%; precision:  58.56%; recall:  36.31%; FB1:  44.83\n",
      "              LOC: precision:  57.26%; recall:  48.09%; FB1:  52.28\n",
      "             MISC: precision:  70.47%; recall:  23.86%; FB1:  35.65\n",
      "              ORG: precision:  52.81%; recall:  39.40%; FB1:  45.13\n",
      "              PER: precision:  62.01%; recall:  32.62%; FB1:  42.75\n",
      "\n",
      "epoch = 34\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 3047 phrases; correct: 1820.\n",
      "accuracy:  92.49%; precision:  59.73%; recall:  37.66%; FB1:  46.19\n",
      "              LOC: precision:  69.12%; recall:  39.80%; FB1:  50.51\n",
      "             MISC: precision:  78.31%; recall:  19.31%; FB1:  30.98\n",
      "              ORG: precision:  55.92%; recall:  38.44%; FB1:  45.56\n",
      "              PER: precision:  53.60%; recall:  48.39%; FB1:  50.86\n",
      "\n",
      "epoch = 35\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2684 phrases; correct: 1693.\n",
      "accuracy:  92.22%; precision:  63.08%; recall:  35.03%; FB1:  45.04\n",
      "              LOC: precision:  60.90%; recall:  47.08%; FB1:  53.10\n",
      "             MISC: precision:  78.20%; recall:  20.59%; FB1:  32.60\n",
      "              ORG: precision:  58.70%; recall:  32.63%; FB1:  41.95\n",
      "              PER: precision:  64.29%; recall:  37.40%; FB1:  47.29\n",
      "\n",
      "epoch = 36\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2696 phrases; correct: 1688.\n",
      "accuracy:  92.21%; precision:  62.61%; recall:  34.93%; FB1:  44.84\n",
      "              LOC: precision:  59.41%; recall:  46.23%; FB1:  52.00\n",
      "             MISC: precision:  72.79%; recall:  21.19%; FB1:  32.82\n",
      "              ORG: precision:  61.15%; recall:  32.47%; FB1:  42.42\n",
      "              PER: precision:  63.71%; recall:  37.47%; FB1:  47.19\n",
      "\n",
      "epoch = 37\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2981 phrases; correct: 1752.\n",
      "accuracy:  92.26%; precision:  58.77%; recall:  36.25%; FB1:  44.84\n",
      "              LOC: precision:  53.29%; recall:  45.98%; FB1:  49.36\n",
      "             MISC: precision:  62.20%; recall:  25.74%; FB1:  36.41\n",
      "              ORG: precision:  60.18%; recall:  32.15%; FB1:  41.91\n",
      "              PER: precision:  62.43%; recall:  39.26%; FB1:  48.20\n",
      "\n",
      "epoch = 38\n",
      "\n",
      "processed 51444 tokens with 4833 phrases; found: 2552 phrases; correct: 1598.\n",
      "accuracy:  92.09%; precision:  62.62%; recall:  33.06%; FB1:  43.28\n",
      "              LOC: precision:  64.41%; recall:  37.09%; FB1:  47.07\n",
      "             MISC: precision:  71.52%; recall:  21.39%; FB1:  32.93\n",
      "              ORG: precision:  56.74%; recall:  35.62%; FB1:  43.76\n",
      "              PER: precision:  63.46%; recall:  35.83%; FB1:  45.80\n",
      "\n",
      "epoch = 39\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-33e9b3b07638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mword_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmm_viterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mw_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mw_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3245e7ea9c59>\u001b[0m in \u001b[0;36mhmm_viterbi\u001b[0;34m(W, words)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mprobility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mPre_Next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_number\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprobility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mnext_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3245e7ea9c59>\u001b[0m in \u001b[0;36mPre_Next\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtp_P_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtp_P_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mif_has_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pt '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m't '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mP_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp_P_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mP_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W = {}\n",
    "epoch = 100\n",
    "for e in range(epoch):\n",
    "    print('epoch = '+ str(e+1))\n",
    "    # training\n",
    "    for sentence in text_train:\n",
    "\n",
    "        words = [' '.join([s[0],s[1]]) for s in sentence]\n",
    "        word_tags = [s[-1] for s in sentence]\n",
    "\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "        w_true = create_features(words, word_tags)\n",
    "        w_pred = create_features(words, y_pred)\n",
    "        for wt in w_true:\n",
    "            if wt in W: W[wt] += w_true[wt]\n",
    "            else: W[wt] = w_true[wt]\n",
    "\n",
    "        for wp in w_pred:\n",
    "            if wp in W: W[wp] -= w_pred[wp]\n",
    "            else: W[wp] = -w_pred[wp]\n",
    "                \n",
    "    # predicting            \n",
    "    filename = 'SPViterbi_5attribs_pos_viterbi_deu.txt'\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    save_wt = '\\n'\n",
    "    for sentence in text_pred:\n",
    "        words = [' '.join([s[0],s[1]]) for s in sentence]\n",
    "        y_pred = hmm_viterbi(W, words)\n",
    "\n",
    "        for wt in range(len(sentence)):\n",
    "            save_wt += sentence[wt][0]+' '+sentence[wt][1]+' '+sentence[wt][2]+' '+sentence[wt][3]+' '+sentence[wt][4]+' '+y_pred[wt]+'\\n'\n",
    "\n",
    "        save_wt += '\\n'\n",
    "\n",
    "    with open('SPViterbi_5attribs_pos_viterbi_deu.txt', 'w+') as txt_file:\n",
    "        txt_file.write(save_wt)\n",
    "\n",
    "    output = subprocess.run(\"/usr/bin/perl -w conlleval < SPViterbi_5attribs_pos_viterbi_deu.txt\", shell=True, stdout=subprocess.PIPE, universal_newlines=True)\n",
    "    print('\\n'+output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
